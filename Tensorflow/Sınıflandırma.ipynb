{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193e218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>...</th>\n",
       "      <th>SOURCE_I</th>\n",
       "      <th>SOURCE_J</th>\n",
       "      <th>SOURCE_K</th>\n",
       "      <th>SOURCE_M</th>\n",
       "      <th>SOURCE_L</th>\n",
       "      <th>SOURCE_N</th>\n",
       "      <th>SOURCE_O</th>\n",
       "      <th>SOURCE_P</th>\n",
       "      <th>SOURCE_R</th>\n",
       "      <th>SOURCE_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23.303047</td>\n",
       "      <td>13.445560</td>\n",
       "      <td>159.066933</td>\n",
       "      <td>1296.628667</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.359585</td>\n",
       "      <td>0.388730</td>\n",
       "      <td>0.190544</td>\n",
       "      <td>0.313341</td>\n",
       "      <td>...</td>\n",
       "      <td>32.875560</td>\n",
       "      <td>22.448127</td>\n",
       "      <td>239.118533</td>\n",
       "      <td>2615.278000</td>\n",
       "      <td>0.210103</td>\n",
       "      <td>0.862174</td>\n",
       "      <td>0.922148</td>\n",
       "      <td>0.343781</td>\n",
       "      <td>0.595983</td>\n",
       "      <td>0.154015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.645007</td>\n",
       "      <td>23.018073</td>\n",
       "      <td>172.149800</td>\n",
       "      <td>1717.612000</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.101865</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.234714</td>\n",
       "      <td>...</td>\n",
       "      <td>32.370380</td>\n",
       "      <td>30.323753</td>\n",
       "      <td>205.698933</td>\n",
       "      <td>2533.672000</td>\n",
       "      <td>0.160362</td>\n",
       "      <td>0.241709</td>\n",
       "      <td>0.312953</td>\n",
       "      <td>240.932000</td>\n",
       "      <td>356.216667</td>\n",
       "      <td>0.115311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25.505113</td>\n",
       "      <td>27.525833</td>\n",
       "      <td>168.393333</td>\n",
       "      <td>1558.286000</td>\n",
       "      <td>0.141969</td>\n",
       "      <td>0.207124</td>\n",
       "      <td>0.255699</td>\n",
       "      <td>0.165673</td>\n",
       "      <td>0.268004</td>\n",
       "      <td>...</td>\n",
       "      <td>30.531007</td>\n",
       "      <td>33.069860</td>\n",
       "      <td>197.538333</td>\n",
       "      <td>2213.724667</td>\n",
       "      <td>0.187046</td>\n",
       "      <td>0.549869</td>\n",
       "      <td>0.583418</td>\n",
       "      <td>314.766000</td>\n",
       "      <td>0.468004</td>\n",
       "      <td>0.113445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.792707</td>\n",
       "      <td>26.398893</td>\n",
       "      <td>100.491960</td>\n",
       "      <td>500.128200</td>\n",
       "      <td>0.184585</td>\n",
       "      <td>0.367745</td>\n",
       "      <td>0.312693</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.336398</td>\n",
       "      <td>...</td>\n",
       "      <td>19.313420</td>\n",
       "      <td>34.326333</td>\n",
       "      <td>128.069607</td>\n",
       "      <td>735.360733</td>\n",
       "      <td>0.271761</td>\n",
       "      <td>1.122147</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.333548</td>\n",
       "      <td>0.859842</td>\n",
       "      <td>224.092667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>26.282313</td>\n",
       "      <td>18.575080</td>\n",
       "      <td>174.999533</td>\n",
       "      <td>1680.047333</td>\n",
       "      <td>0.129922</td>\n",
       "      <td>0.172020</td>\n",
       "      <td>256.476000</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.234326</td>\n",
       "      <td>...</td>\n",
       "      <td>29.196813</td>\n",
       "      <td>21.593207</td>\n",
       "      <td>197.149733</td>\n",
       "      <td>2040.150000</td>\n",
       "      <td>0.177979</td>\n",
       "      <td>265.543333</td>\n",
       "      <td>0.518133</td>\n",
       "      <td>0.210492</td>\n",
       "      <td>0.306217</td>\n",
       "      <td>0.099456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>27.927387</td>\n",
       "      <td>29.002513</td>\n",
       "      <td>183.937333</td>\n",
       "      <td>1915.798000</td>\n",
       "      <td>143.782000</td>\n",
       "      <td>0.150129</td>\n",
       "      <td>0.315932</td>\n",
       "      <td>0.179922</td>\n",
       "      <td>0.223575</td>\n",
       "      <td>...</td>\n",
       "      <td>32.966233</td>\n",
       "      <td>34.196800</td>\n",
       "      <td>215.154867</td>\n",
       "      <td>2625.640667</td>\n",
       "      <td>182.642000</td>\n",
       "      <td>0.273704</td>\n",
       "      <td>0.531993</td>\n",
       "      <td>0.287046</td>\n",
       "      <td>266.838667</td>\n",
       "      <td>0.092163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>26.075060</td>\n",
       "      <td>36.593167</td>\n",
       "      <td>169.947733</td>\n",
       "      <td>1633.415333</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.133937</td>\n",
       "      <td>186.528000</td>\n",
       "      <td>0.126826</td>\n",
       "      <td>0.226942</td>\n",
       "      <td>...</td>\n",
       "      <td>30.686447</td>\n",
       "      <td>49.546500</td>\n",
       "      <td>200.776667</td>\n",
       "      <td>2242.222000</td>\n",
       "      <td>0.151036</td>\n",
       "      <td>0.248963</td>\n",
       "      <td>0.416450</td>\n",
       "      <td>0.210880</td>\n",
       "      <td>0.333160</td>\n",
       "      <td>0.085971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>21.502533</td>\n",
       "      <td>36.372960</td>\n",
       "      <td>140.284600</td>\n",
       "      <td>1111.525533</td>\n",
       "      <td>0.109520</td>\n",
       "      <td>0.132513</td>\n",
       "      <td>0.119831</td>\n",
       "      <td>0.068679</td>\n",
       "      <td>205.958000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.585427</td>\n",
       "      <td>44.196773</td>\n",
       "      <td>164.118733</td>\n",
       "      <td>1455.954667</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>0.440802</td>\n",
       "      <td>0.183678</td>\n",
       "      <td>0.287305</td>\n",
       "      <td>0.101295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>26.683867</td>\n",
       "      <td>37.992127</td>\n",
       "      <td>181.476200</td>\n",
       "      <td>1638.596667</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>358.807333</td>\n",
       "      <td>0.455180</td>\n",
       "      <td>196.890667</td>\n",
       "      <td>0.310491</td>\n",
       "      <td>...</td>\n",
       "      <td>33.341880</td>\n",
       "      <td>51.062040</td>\n",
       "      <td>239.118533</td>\n",
       "      <td>2358.802000</td>\n",
       "      <td>213.730000</td>\n",
       "      <td>1.124479</td>\n",
       "      <td>1.215929</td>\n",
       "      <td>343.263333</td>\n",
       "      <td>0.529403</td>\n",
       "      <td>160.621333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0</td>\n",
       "      <td>10.051787</td>\n",
       "      <td>31.787480</td>\n",
       "      <td>62.072373</td>\n",
       "      <td>234.455333</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205569</td>\n",
       "      <td>...</td>\n",
       "      <td>12248.672000</td>\n",
       "      <td>39.339273</td>\n",
       "      <td>76.631920</td>\n",
       "      <td>347.926533</td>\n",
       "      <td>0.116528</td>\n",
       "      <td>0.083471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371890</td>\n",
       "      <td>0.091179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS  TCP_CONVERSATION_EXCHANGE  \\\n",
       "0       1   23.303047                  13.445560                 159.066933   \n",
       "1       1   26.645007                  23.018073                 172.149800   \n",
       "2       1   25.505113                  27.525833                 168.393333   \n",
       "3       1   14.792707                  26.398893                 100.491960   \n",
       "4       1   26.282313                  18.575080                 174.999533   \n",
       "..    ...         ...                        ...                        ...   \n",
       "543     1   27.927387                  29.002513                 183.937333   \n",
       "544     1   26.075060                  36.593167                 169.947733   \n",
       "545     1   21.502533                  36.372960                 140.284600   \n",
       "546     1   26.683867                  37.992127                 181.476200   \n",
       "547     0   10.051787                  31.787480                  62.072373   \n",
       "\n",
       "     DIST_REMOTE_TCP_PORT  REMOTE_IPS   APP_BYTES  SOURCE_APP_PACKETS  \\\n",
       "0             1296.628667    0.153367    0.359585            0.388730   \n",
       "1             1717.612000    0.109767    0.101865            0.112564   \n",
       "2             1558.286000    0.141969    0.207124            0.255699   \n",
       "3              500.128200    0.184585    0.367745            0.312693   \n",
       "4             1680.047333    0.129922    0.172020          256.476000   \n",
       "..                    ...         ...         ...                 ...   \n",
       "543           1915.798000  143.782000    0.150129            0.315932   \n",
       "544           1633.415333    0.126684    0.133937          186.528000   \n",
       "545           1111.525533    0.109520    0.132513            0.119831   \n",
       "546           1638.596667    0.152590  358.807333            0.455180   \n",
       "547            234.455333    0.068173    0.056502            0.000000   \n",
       "\n",
       "     REMOTE_APP_PACKETS  SOURCE_APP_BYTES  ...      SOURCE_I   SOURCE_J  \\\n",
       "0              0.190544          0.313341  ...     32.875560  22.448127   \n",
       "1              0.090894          0.234714  ...     32.370380  30.323753   \n",
       "2              0.165673          0.268004  ...     30.531007  33.069860   \n",
       "3              0.136269          0.336398  ...     19.313420  34.326333   \n",
       "4              0.135103          0.234326  ...     29.196813  21.593207   \n",
       "..                  ...               ...  ...           ...        ...   \n",
       "543            0.179922          0.223575  ...     32.966233  34.196800   \n",
       "544            0.126826          0.226942  ...     30.686447  49.546500   \n",
       "545            0.068679        205.958000  ...     24.585427  44.196773   \n",
       "546          196.890667          0.310491  ...     33.341880  51.062040   \n",
       "547            0.000000          0.205569  ...  12248.672000  39.339273   \n",
       "\n",
       "       SOURCE_K     SOURCE_M    SOURCE_L    SOURCE_N  SOURCE_O    SOURCE_P  \\\n",
       "0    239.118533  2615.278000    0.210103    0.862174  0.922148    0.343781   \n",
       "1    205.698933  2533.672000    0.160362    0.241709  0.312953  240.932000   \n",
       "2    197.538333  2213.724667    0.187046    0.549869  0.583418  314.766000   \n",
       "3    128.069607   735.360733    0.271761    1.122147  0.889764    0.333548   \n",
       "4    197.149733  2040.150000    0.177979  265.543333  0.518133    0.210492   \n",
       "..          ...          ...         ...         ...       ...         ...   \n",
       "543  215.154867  2625.640667  182.642000    0.273704  0.531993    0.287046   \n",
       "544  200.776667  2242.222000    0.151036    0.248963  0.416450    0.210880   \n",
       "545  164.118733  1455.954667    0.147538    0.400776  0.440802    0.183678   \n",
       "546  239.118533  2358.802000  213.730000    1.124479  1.215929  343.263333   \n",
       "547   76.631920   347.926533    0.116528    0.083471  0.000000    0.000000   \n",
       "\n",
       "       SOURCE_R    SOURCE_S  \n",
       "0      0.595983    0.154015  \n",
       "1    356.216667    0.115311  \n",
       "2      0.468004    0.113445  \n",
       "3      0.859842  224.092667  \n",
       "4      0.306217    0.099456  \n",
       "..          ...         ...  \n",
       "543  266.838667    0.092163  \n",
       "544    0.333160    0.085971  \n",
       "545    0.287305    0.101295  \n",
       "546    0.529403  160.621333  \n",
       "547    0.371890    0.091179  \n",
       "\n",
       "[548 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataFrame = pd.read_excel(\"maliciousornot.xlsx\")\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1539b293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>URL_LENGTH</th>\n",
       "      <th>NUMBER_SPECIAL_CHARACTERS</th>\n",
       "      <th>TCP_CONVERSATION_EXCHANGE</th>\n",
       "      <th>DIST_REMOTE_TCP_PORT</th>\n",
       "      <th>REMOTE_IPS</th>\n",
       "      <th>APP_BYTES</th>\n",
       "      <th>SOURCE_APP_PACKETS</th>\n",
       "      <th>REMOTE_APP_PACKETS</th>\n",
       "      <th>SOURCE_APP_BYTES</th>\n",
       "      <th>...</th>\n",
       "      <th>SOURCE_I</th>\n",
       "      <th>SOURCE_J</th>\n",
       "      <th>SOURCE_K</th>\n",
       "      <th>SOURCE_M</th>\n",
       "      <th>SOURCE_L</th>\n",
       "      <th>SOURCE_N</th>\n",
       "      <th>SOURCE_O</th>\n",
       "      <th>SOURCE_P</th>\n",
       "      <th>SOURCE_R</th>\n",
       "      <th>SOURCE_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383212</td>\n",
       "      <td>949.973475</td>\n",
       "      <td>25.015747</td>\n",
       "      <td>119.725438</td>\n",
       "      <td>857.123249</td>\n",
       "      <td>5.785481</td>\n",
       "      <td>6.499737</td>\n",
       "      <td>10.069604</td>\n",
       "      <td>3.181365</td>\n",
       "      <td>22.809689</td>\n",
       "      <td>...</td>\n",
       "      <td>399.714125</td>\n",
       "      <td>33.295952</td>\n",
       "      <td>139.830855</td>\n",
       "      <td>1155.666380</td>\n",
       "      <td>14.295530</td>\n",
       "      <td>32.855845</td>\n",
       "      <td>34.913670</td>\n",
       "      <td>11.758580</td>\n",
       "      <td>40.829159</td>\n",
       "      <td>2.637820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486613</td>\n",
       "      <td>3202.802599</td>\n",
       "      <td>5.605685</td>\n",
       "      <td>31.842845</td>\n",
       "      <td>461.579998</td>\n",
       "      <td>27.796268</td>\n",
       "      <td>35.390031</td>\n",
       "      <td>46.976527</td>\n",
       "      <td>21.315640</td>\n",
       "      <td>70.942060</td>\n",
       "      <td>...</td>\n",
       "      <td>2117.405314</td>\n",
       "      <td>7.956699</td>\n",
       "      <td>44.017609</td>\n",
       "      <td>746.777340</td>\n",
       "      <td>49.075477</td>\n",
       "      <td>126.026487</td>\n",
       "      <td>149.880701</td>\n",
       "      <td>52.045464</td>\n",
       "      <td>119.531119</td>\n",
       "      <td>19.086225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.051787</td>\n",
       "      <td>12.577687</td>\n",
       "      <td>56.722647</td>\n",
       "      <td>185.880333</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.025104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151165</td>\n",
       "      <td>...</td>\n",
       "      <td>10.271993</td>\n",
       "      <td>15.569907</td>\n",
       "      <td>65.297753</td>\n",
       "      <td>239.895733</td>\n",
       "      <td>0.105246</td>\n",
       "      <td>0.044456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202720</td>\n",
       "      <td>0.071295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.838688</td>\n",
       "      <td>20.987638</td>\n",
       "      <td>97.470595</td>\n",
       "      <td>544.622900</td>\n",
       "      <td>0.112309</td>\n",
       "      <td>0.084718</td>\n",
       "      <td>0.038394</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.211755</td>\n",
       "      <td>...</td>\n",
       "      <td>17.082208</td>\n",
       "      <td>27.325057</td>\n",
       "      <td>108.999062</td>\n",
       "      <td>667.971017</td>\n",
       "      <td>0.154501</td>\n",
       "      <td>0.196275</td>\n",
       "      <td>0.152558</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>0.331022</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.069900</td>\n",
       "      <td>24.423510</td>\n",
       "      <td>112.920683</td>\n",
       "      <td>723.637967</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>0.122720</td>\n",
       "      <td>0.085395</td>\n",
       "      <td>0.045304</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>...</td>\n",
       "      <td>19.838030</td>\n",
       "      <td>32.972710</td>\n",
       "      <td>127.117537</td>\n",
       "      <td>901.616767</td>\n",
       "      <td>0.173899</td>\n",
       "      <td>0.297149</td>\n",
       "      <td>0.328950</td>\n",
       "      <td>0.132318</td>\n",
       "      <td>0.374869</td>\n",
       "      <td>0.103743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.264187</td>\n",
       "      <td>28.270650</td>\n",
       "      <td>137.175800</td>\n",
       "      <td>1037.270550</td>\n",
       "      <td>0.137694</td>\n",
       "      <td>0.172215</td>\n",
       "      <td>0.189799</td>\n",
       "      <td>0.101201</td>\n",
       "      <td>0.266159</td>\n",
       "      <td>...</td>\n",
       "      <td>25.919620</td>\n",
       "      <td>38.698083</td>\n",
       "      <td>164.636867</td>\n",
       "      <td>1460.488333</td>\n",
       "      <td>0.194689</td>\n",
       "      <td>0.497797</td>\n",
       "      <td>0.559098</td>\n",
       "      <td>0.223866</td>\n",
       "      <td>0.430342</td>\n",
       "      <td>0.119375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12828.981333</td>\n",
       "      <td>50.880693</td>\n",
       "      <td>244.170333</td>\n",
       "      <td>3239.628667</td>\n",
       "      <td>159.326000</td>\n",
       "      <td>358.807333</td>\n",
       "      <td>405.439333</td>\n",
       "      <td>209.844000</td>\n",
       "      <td>393.781333</td>\n",
       "      <td>...</td>\n",
       "      <td>12928.722000</td>\n",
       "      <td>64.170813</td>\n",
       "      <td>325.387733</td>\n",
       "      <td>5510.348000</td>\n",
       "      <td>239.636667</td>\n",
       "      <td>1370.462667</td>\n",
       "      <td>1621.757333</td>\n",
       "      <td>376.942000</td>\n",
       "      <td>704.661333</td>\n",
       "      <td>224.092667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Type    URL_LENGTH  NUMBER_SPECIAL_CHARACTERS  \\\n",
       "count  548.000000    548.000000                 548.000000   \n",
       "mean     0.383212    949.973475                  25.015747   \n",
       "std      0.486613   3202.802599                   5.605685   \n",
       "min      0.000000     10.051787                  12.577687   \n",
       "25%      0.000000     15.838688                  20.987638   \n",
       "50%      0.000000     18.069900                  24.423510   \n",
       "75%      1.000000     23.264187                  28.270650   \n",
       "max      1.000000  12828.981333                  50.880693   \n",
       "\n",
       "       TCP_CONVERSATION_EXCHANGE  DIST_REMOTE_TCP_PORT  REMOTE_IPS  \\\n",
       "count                 548.000000            548.000000  548.000000   \n",
       "mean                  119.725438            857.123249    5.785481   \n",
       "std                    31.842845            461.579998   27.796268   \n",
       "min                    56.722647            185.880333    0.068173   \n",
       "25%                    97.470595            544.622900    0.112309   \n",
       "50%                   112.920683            723.637967    0.125084   \n",
       "75%                   137.175800           1037.270550    0.137694   \n",
       "max                   244.170333           3239.628667  159.326000   \n",
       "\n",
       "        APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  SOURCE_APP_BYTES  \\\n",
       "count  548.000000          548.000000          548.000000        548.000000   \n",
       "mean     6.499737           10.069604            3.181365         22.809689   \n",
       "std     35.390031           46.976527           21.315640         70.942060   \n",
       "min      0.025104            0.000000            0.000000          0.151165   \n",
       "25%      0.084718            0.038394            0.026383          0.211755   \n",
       "50%      0.122720            0.085395            0.045304          0.235168   \n",
       "75%      0.172215            0.189799            0.101201          0.266159   \n",
       "max    358.807333          405.439333          209.844000        393.781333   \n",
       "\n",
       "       ...      SOURCE_I    SOURCE_J    SOURCE_K     SOURCE_M    SOURCE_L  \\\n",
       "count  ...    548.000000  548.000000  548.000000   548.000000  548.000000   \n",
       "mean   ...    399.714125   33.295952  139.830855  1155.666380   14.295530   \n",
       "std    ...   2117.405314    7.956699   44.017609   746.777340   49.075477   \n",
       "min    ...     10.271993   15.569907   65.297753   239.895733    0.105246   \n",
       "25%    ...     17.082208   27.325057  108.999062   667.971017    0.154501   \n",
       "50%    ...     19.838030   32.972710  127.117537   901.616767    0.173899   \n",
       "75%    ...     25.919620   38.698083  164.636867  1460.488333    0.194689   \n",
       "max    ...  12928.722000   64.170813  325.387733  5510.348000  239.636667   \n",
       "\n",
       "          SOURCE_N     SOURCE_O    SOURCE_P    SOURCE_R    SOURCE_S  \n",
       "count   548.000000   548.000000  548.000000  548.000000  548.000000  \n",
       "mean     32.855845    34.913670   11.758580   40.829159    2.637820  \n",
       "std     126.026487   149.880701   52.045464  119.531119   19.086225  \n",
       "min       0.044456     0.000000    0.000000    0.202720    0.071295  \n",
       "25%       0.196275     0.152558    0.084805    0.331022    0.093099  \n",
       "50%       0.297149     0.328950    0.132318    0.374869    0.103743  \n",
       "75%       0.497797     0.559098    0.223866    0.430342    0.119375  \n",
       "max    1370.462667  1621.757333  376.942000  704.661333  224.092667  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.describe() # Type=1 zararlı yazılım, Type=0 zararsız yazılım demektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e654b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.sort_values of Type                         1.000000\n",
       "URL_LENGTH                  -0.228422\n",
       "NUMBER_SPECIAL_CHARACTERS    0.412095\n",
       "TCP_CONVERSATION_EXCHANGE    0.744570\n",
       "DIST_REMOTE_TCP_PORT         0.710294\n",
       "REMOTE_IPS                   0.126232\n",
       "APP_BYTES                    0.096659\n",
       "SOURCE_APP_PACKETS           0.129433\n",
       "REMOTE_APP_PACKETS           0.139874\n",
       "SOURCE_APP_BYTES            -0.086080\n",
       "REMOTE_APP_BYTES            -0.048806\n",
       "APP_PACKETS                  0.240818\n",
       "DNS_QUERY_TIMES             -0.011055\n",
       "SOURCE_A                     0.536539\n",
       "SOURCE_B                    -0.128587\n",
       "SOURCE_C                    -0.075369\n",
       "SOURCE_D                     0.029479\n",
       "SOURCE_F                    -0.007551\n",
       "SOURCE_E                     0.001985\n",
       "SOURCE_G                    -0.017433\n",
       "SOURCE_H                     0.055045\n",
       "SOURCE_I                    -0.138708\n",
       "SOURCE_J                     0.453197\n",
       "SOURCE_K                     0.784173\n",
       "SOURCE_M                     0.734002\n",
       "SOURCE_L                     0.022932\n",
       "SOURCE_N                     0.088076\n",
       "SOURCE_O                     0.063622\n",
       "SOURCE_P                     0.205141\n",
       "SOURCE_R                     0.069140\n",
       "SOURCE_S                     0.141134\n",
       "Name: Type, dtype: float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.corr()[\"Type\"].sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db69f545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Type', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "sbn.countplot(x=\"Type\",data=dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e2cc446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataFrame[\"Type\"].values\n",
    "x=dataFrame.drop(\"Type\",axis=1).values # axis 1 demek tüm kolonu düşür demek\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=15)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4995bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd548b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f085dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.6928WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6739 - val_loss: 0.6671\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6493 - val_loss: 0.6480\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.6199\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5838 - val_loss: 0.5929\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.5555\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4943 - val_loss: 0.5124\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4443 - val_loss: 0.4743\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4411\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3563 - val_loss: 0.4082\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3771\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2875 - val_loss: 0.3645\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2586 - val_loss: 0.3315\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2326 - val_loss: 0.3205\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2107 - val_loss: 0.2961\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.3065\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1815 - val_loss: 0.2788\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1702 - val_loss: 0.2896\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.2639\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.2758\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.2682\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.2413\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.2584\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1321 - val_loss: 0.2341\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 0.2428\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.2255\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.2485\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1129 - val_loss: 0.2230\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.2292\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1130 - val_loss: 0.2223\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1113 - val_loss: 0.2344\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.2234\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.2246\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.2211\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.2216\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.2186\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.2286\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.2154\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.2184\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.2170\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.2124\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.2188\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0975 - val_loss: 0.2253\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.2221\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.2150\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.2170\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.2373\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.2105\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.2280\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.2164\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.2226\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.2235\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.2119\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.2140\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.2250\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.2163\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.2247\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.2221\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.2180\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.2132\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.2273\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.2223\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.2478\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.2186\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.2275\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.2171\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.2252\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.2247\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.2338\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.2229\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.2443\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.2251\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.2394\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.2220\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.2490\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.2303\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.2380\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.2267\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.2604\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.2349\n",
      "Epoch 80/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.2518\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.2321\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.2317\n",
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.2314\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.2551\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.2251\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.2345\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.2367\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.2427\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.2369\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.2373\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.2413\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.2385\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.2468\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.2356\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.2462\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.2402\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.2493\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.2620\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.2451\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.2362\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.2467\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.2580\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.2463\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.2346\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.2409\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.2479\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.2449\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.2471\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.2490\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.2448\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.2511\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.2475\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.2592\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.2304\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.2688\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.2334\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.2305\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.2535\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.2335\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.2535\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.2378\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.2382\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.2458\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.2402\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.2592\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.2532\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.2679\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.2519\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.2579\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.2427\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.2870\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.2556\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.2420\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.2653\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.2570\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.2698\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.2620\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.2735\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.2599\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.3063\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.2672\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.2792\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.2758\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.2952\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.2592\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.2738\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.2627\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.2804\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.2714\n",
      "Epoch 150/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.3101\n",
      "Epoch 151/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.2691\n",
      "Epoch 152/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.3022\n",
      "Epoch 153/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.2767\n",
      "Epoch 154/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.3029\n",
      "Epoch 155/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.2774\n",
      "Epoch 156/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.2905\n",
      "Epoch 157/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.2810\n",
      "Epoch 158/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.3157\n",
      "Epoch 159/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.2972\n",
      "Epoch 160/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.3277\n",
      "Epoch 161/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.2969\n",
      "Epoch 162/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.3060\n",
      "Epoch 163/700\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0389 - val_loss: 0.3003\n",
      "Epoch 164/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.2902\n",
      "Epoch 165/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.3038\n",
      "Epoch 166/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.2924\n",
      "Epoch 167/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.3158\n",
      "Epoch 168/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.3026\n",
      "Epoch 169/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.3294\n",
      "Epoch 170/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.2964\n",
      "Epoch 171/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.3109\n",
      "Epoch 172/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.3167\n",
      "Epoch 173/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.3207\n",
      "Epoch 174/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.3229\n",
      "Epoch 175/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.3148\n",
      "Epoch 176/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.2861\n",
      "Epoch 177/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3139\n",
      "Epoch 178/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.3082\n",
      "Epoch 179/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.3211\n",
      "Epoch 180/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.3182\n",
      "Epoch 181/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.3175\n",
      "Epoch 182/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.3327\n",
      "Epoch 183/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.3269\n",
      "Epoch 184/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.3362\n",
      "Epoch 185/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.3201\n",
      "Epoch 186/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3471\n",
      "Epoch 187/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.3415\n",
      "Epoch 188/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.3278\n",
      "Epoch 189/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.3488\n",
      "Epoch 190/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.3109\n",
      "Epoch 191/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.3269\n",
      "Epoch 192/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.3510\n",
      "Epoch 193/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.3296\n",
      "Epoch 194/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.3390\n",
      "Epoch 195/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.3282\n",
      "Epoch 196/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.3680\n",
      "Epoch 197/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.3397\n",
      "Epoch 198/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.3608\n",
      "Epoch 199/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.3573\n",
      "Epoch 200/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.3518\n",
      "Epoch 201/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.3425\n",
      "Epoch 202/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.3649\n",
      "Epoch 203/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.3777\n",
      "Epoch 204/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.3424\n",
      "Epoch 205/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.3537\n",
      "Epoch 206/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.3703\n",
      "Epoch 207/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.3679\n",
      "Epoch 208/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.3734\n",
      "Epoch 209/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.3670\n",
      "Epoch 210/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.3786\n",
      "Epoch 211/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.3534\n",
      "Epoch 212/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.4040\n",
      "Epoch 213/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3518\n",
      "Epoch 214/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3630\n",
      "Epoch 215/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.3755\n",
      "Epoch 216/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.3472\n",
      "Epoch 217/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.3998\n",
      "Epoch 218/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.3628\n",
      "Epoch 219/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.3721\n",
      "Epoch 220/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.3629\n",
      "Epoch 221/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.3592\n",
      "Epoch 222/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.3572\n",
      "Epoch 223/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.3507\n",
      "Epoch 224/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.3691\n",
      "Epoch 225/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.3514\n",
      "Epoch 226/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.3581\n",
      "Epoch 227/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.3606\n",
      "Epoch 228/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.3535\n",
      "Epoch 229/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.3486\n",
      "Epoch 230/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.3783\n",
      "Epoch 231/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.3749\n",
      "Epoch 232/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.3322\n",
      "Epoch 233/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.3280\n",
      "Epoch 234/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.3388\n",
      "Epoch 235/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.3702\n",
      "Epoch 236/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.3514\n",
      "Epoch 237/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.3675\n",
      "Epoch 238/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.3791\n",
      "Epoch 239/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.3635\n",
      "Epoch 240/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.3633\n",
      "Epoch 241/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.3778\n",
      "Epoch 242/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.3738\n",
      "Epoch 243/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.3496\n",
      "Epoch 244/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.3761\n",
      "Epoch 245/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.3603\n",
      "Epoch 246/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.3676\n",
      "Epoch 247/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.3853\n",
      "Epoch 248/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.3715\n",
      "Epoch 249/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.3801\n",
      "Epoch 250/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.3766\n",
      "Epoch 251/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.3780\n",
      "Epoch 252/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.3787\n",
      "Epoch 253/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.3677\n",
      "Epoch 254/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.4122\n",
      "Epoch 255/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.3712\n",
      "Epoch 256/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.3984\n",
      "Epoch 257/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.3808\n",
      "Epoch 258/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.3905\n",
      "Epoch 259/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.3699\n",
      "Epoch 260/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.3793\n",
      "Epoch 261/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.3685\n",
      "Epoch 262/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.3704\n",
      "Epoch 263/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.3595\n",
      "Epoch 264/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.3800\n",
      "Epoch 265/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.3756\n",
      "Epoch 266/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.3855\n",
      "Epoch 267/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.3824\n",
      "Epoch 268/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.3825\n",
      "Epoch 269/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.3891\n",
      "Epoch 270/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.3798\n",
      "Epoch 271/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.3822\n",
      "Epoch 272/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.3900\n",
      "Epoch 273/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.3809\n",
      "Epoch 274/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.3899\n",
      "Epoch 275/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.3970\n",
      "Epoch 276/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.3859\n",
      "Epoch 277/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.4096\n",
      "Epoch 278/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.3889\n",
      "Epoch 279/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.3946\n",
      "Epoch 280/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.4009\n",
      "Epoch 281/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.3918\n",
      "Epoch 282/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.4010\n",
      "Epoch 283/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.3858\n",
      "Epoch 284/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.3690\n",
      "Epoch 285/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.3813\n",
      "Epoch 286/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.3698\n",
      "Epoch 287/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.3766\n",
      "Epoch 288/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.3896\n",
      "Epoch 289/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.3965\n",
      "Epoch 290/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.3956\n",
      "Epoch 291/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.4071\n",
      "Epoch 292/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.4014\n",
      "Epoch 293/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.4083\n",
      "Epoch 294/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.3960\n",
      "Epoch 295/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.4076\n",
      "Epoch 296/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.4179\n",
      "Epoch 297/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.4136\n",
      "Epoch 298/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.4104\n",
      "Epoch 299/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.4196\n",
      "Epoch 300/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.4085\n",
      "Epoch 301/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.4184\n",
      "Epoch 302/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.4073\n",
      "Epoch 303/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.4138\n",
      "Epoch 304/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.4146\n",
      "Epoch 305/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.4175\n",
      "Epoch 306/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.4132\n",
      "Epoch 307/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.4257\n",
      "Epoch 308/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.4171\n",
      "Epoch 309/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.4247\n",
      "Epoch 310/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.4226\n",
      "Epoch 311/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.4252\n",
      "Epoch 312/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.4188\n",
      "Epoch 313/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.4275\n",
      "Epoch 314/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.4233\n",
      "Epoch 315/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.4329\n",
      "Epoch 316/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.4419\n",
      "Epoch 317/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.4174\n",
      "Epoch 318/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.4186\n",
      "Epoch 319/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.4175\n",
      "Epoch 320/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.4187\n",
      "Epoch 321/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.4235\n",
      "Epoch 322/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.4284\n",
      "Epoch 323/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.4270\n",
      "Epoch 324/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.4292\n",
      "Epoch 325/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.4382\n",
      "Epoch 326/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.4361\n",
      "Epoch 327/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.4494\n",
      "Epoch 328/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.4362\n",
      "Epoch 329/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.4397\n",
      "Epoch 330/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.4393\n",
      "Epoch 331/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.4443\n",
      "Epoch 332/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.4456\n",
      "Epoch 333/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.4330\n",
      "Epoch 334/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.4429\n",
      "Epoch 335/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.4373\n",
      "Epoch 336/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.4418\n",
      "Epoch 337/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.4429\n",
      "Epoch 338/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.4520\n",
      "Epoch 339/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.4439\n",
      "Epoch 340/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.4391\n",
      "Epoch 341/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.4212\n",
      "Epoch 342/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.4427\n",
      "Epoch 343/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.4200\n",
      "Epoch 344/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.4263\n",
      "Epoch 345/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.4252\n",
      "Epoch 346/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.4227\n",
      "Epoch 347/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.4286\n",
      "Epoch 348/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.4248\n",
      "Epoch 349/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.4382\n",
      "Epoch 350/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.4337\n",
      "Epoch 351/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.4339\n",
      "Epoch 352/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.4468\n",
      "Epoch 353/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.4362\n",
      "Epoch 354/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.4440\n",
      "Epoch 355/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.4551\n",
      "Epoch 356/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.4260\n",
      "Epoch 357/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.4424\n",
      "Epoch 358/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.4307\n",
      "Epoch 359/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.4734\n",
      "Epoch 360/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.4295\n",
      "Epoch 361/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.4395\n",
      "Epoch 362/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.4383\n",
      "Epoch 363/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.4342\n",
      "Epoch 364/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.4552\n",
      "Epoch 365/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.4464\n",
      "Epoch 366/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.4549\n",
      "Epoch 367/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.4526\n",
      "Epoch 368/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.4486\n",
      "Epoch 369/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.4574\n",
      "Epoch 370/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.4421\n",
      "Epoch 371/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.4451\n",
      "Epoch 372/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.4592\n",
      "Epoch 373/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.4667\n",
      "Epoch 374/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.4566\n",
      "Epoch 375/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.4603\n",
      "Epoch 376/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.4573\n",
      "Epoch 377/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.4568\n",
      "Epoch 378/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4629\n",
      "Epoch 379/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4535\n",
      "Epoch 380/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.4704\n",
      "Epoch 381/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.4592\n",
      "Epoch 382/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.4608\n",
      "Epoch 383/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.4689\n",
      "Epoch 384/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.4673\n",
      "Epoch 385/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4637\n",
      "Epoch 386/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.4731\n",
      "Epoch 387/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.4640\n",
      "Epoch 388/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.4731\n",
      "Epoch 389/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.4741\n",
      "Epoch 390/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.4757\n",
      "Epoch 391/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.4673\n",
      "Epoch 392/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.5032\n",
      "Epoch 393/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.4663\n",
      "Epoch 394/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.5117\n",
      "Epoch 395/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.4588\n",
      "Epoch 396/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.4682\n",
      "Epoch 397/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.4634\n",
      "Epoch 398/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.4768\n",
      "Epoch 399/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.4770\n",
      "Epoch 400/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.4920\n",
      "Epoch 401/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.4773\n",
      "Epoch 402/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.4975\n",
      "Epoch 403/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.4869\n",
      "Epoch 404/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.4893\n",
      "Epoch 405/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.4891\n",
      "Epoch 406/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.4869\n",
      "Epoch 407/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.4912\n",
      "Epoch 408/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.4887\n",
      "Epoch 409/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.4903\n",
      "Epoch 410/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.4930\n",
      "Epoch 411/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.4942\n",
      "Epoch 412/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.4986\n",
      "Epoch 413/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.4937\n",
      "Epoch 414/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.4956\n",
      "Epoch 415/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.5065\n",
      "Epoch 416/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.4896\n",
      "Epoch 417/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.5000\n",
      "Epoch 418/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.4867\n",
      "Epoch 419/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.4859\n",
      "Epoch 420/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.4937\n",
      "Epoch 421/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.4938\n",
      "Epoch 422/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.5235\n",
      "Epoch 423/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.4936\n",
      "Epoch 424/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.5039\n",
      "Epoch 425/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.5032\n",
      "Epoch 426/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.4930\n",
      "Epoch 427/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.5105\n",
      "Epoch 428/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.5042\n",
      "Epoch 429/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.5156\n",
      "Epoch 430/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.4998\n",
      "Epoch 431/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.5049\n",
      "Epoch 432/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.5082\n",
      "Epoch 433/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.5012\n",
      "Epoch 434/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.5181\n",
      "Epoch 435/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.5078\n",
      "Epoch 436/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.5120\n",
      "Epoch 437/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.5084\n",
      "Epoch 438/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.5151\n",
      "Epoch 439/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5123\n",
      "Epoch 440/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5086\n",
      "Epoch 441/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.5090\n",
      "Epoch 442/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.5294\n",
      "Epoch 443/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5068\n",
      "Epoch 444/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.5286\n",
      "Epoch 445/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.5071\n",
      "Epoch 446/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.5190\n",
      "Epoch 447/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.5195\n",
      "Epoch 448/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5135\n",
      "Epoch 449/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.5216\n",
      "Epoch 450/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.5210\n",
      "Epoch 451/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5220\n",
      "Epoch 452/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.5171\n",
      "Epoch 453/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.5178\n",
      "Epoch 454/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5284\n",
      "Epoch 455/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5181\n",
      "Epoch 456/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.5159\n",
      "Epoch 457/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0015 - val_loss: 0.5271\n",
      "Epoch 458/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.5267\n",
      "Epoch 459/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.5193\n",
      "Epoch 460/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.5356\n",
      "Epoch 461/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.5240\n",
      "Epoch 462/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.5293\n",
      "Epoch 463/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.5381\n",
      "Epoch 464/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.5276\n",
      "Epoch 465/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.5255\n",
      "Epoch 466/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5378\n",
      "Epoch 467/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5251\n",
      "Epoch 468/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5245\n",
      "Epoch 469/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5286\n",
      "Epoch 470/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.5282\n",
      "Epoch 471/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.5265\n",
      "Epoch 472/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.5298\n",
      "Epoch 473/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9612e-04 - val_loss: 0.5342\n",
      "Epoch 474/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.5277\n",
      "Epoch 475/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.7782e-04 - val_loss: 0.5333\n",
      "Epoch 476/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.5317\n",
      "Epoch 477/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.8573e-04 - val_loss: 0.5370\n",
      "Epoch 478/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.5389\n",
      "Epoch 479/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5421\n",
      "Epoch 480/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.9389e-04 - val_loss: 0.5355\n",
      "Epoch 481/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.5436\n",
      "Epoch 482/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.4457e-04 - val_loss: 0.5351\n",
      "Epoch 483/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.5473\n",
      "Epoch 484/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5405\n",
      "Epoch 485/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5443\n",
      "Epoch 486/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.5456\n",
      "Epoch 487/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.2989e-04 - val_loss: 0.5484\n",
      "Epoch 488/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.5534\n",
      "Epoch 489/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2535e-04 - val_loss: 0.5469\n",
      "Epoch 490/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7089e-04 - val_loss: 0.5457\n",
      "Epoch 491/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.6927e-04 - val_loss: 0.5529\n",
      "Epoch 492/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5934e-04 - val_loss: 0.5500\n",
      "Epoch 493/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4169e-04 - val_loss: 0.5508\n",
      "Epoch 494/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2676e-04 - val_loss: 0.5501\n",
      "Epoch 495/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.8078e-04 - val_loss: 0.5488\n",
      "Epoch 496/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4551e-04 - val_loss: 0.5560\n",
      "Epoch 497/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.3309e-04 - val_loss: 0.5500\n",
      "Epoch 498/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.4718e-04 - val_loss: 0.5576\n",
      "Epoch 499/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2934e-04 - val_loss: 0.5623\n",
      "Epoch 500/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6501e-04 - val_loss: 0.5516\n",
      "Epoch 501/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.8109e-04 - val_loss: 0.5686\n",
      "Epoch 502/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0734e-04 - val_loss: 0.5450\n",
      "Epoch 503/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1340e-04 - val_loss: 0.5466\n",
      "Epoch 504/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7264e-04 - val_loss: 0.5505\n",
      "Epoch 505/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9836e-04 - val_loss: 0.5551\n",
      "Epoch 506/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9753e-04 - val_loss: 0.5614\n",
      "Epoch 507/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2104e-04 - val_loss: 0.5573\n",
      "Epoch 508/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7107e-04 - val_loss: 0.5671\n",
      "Epoch 509/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3159e-04 - val_loss: 0.5657\n",
      "Epoch 510/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7689e-04 - val_loss: 0.5680\n",
      "Epoch 511/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2228e-04 - val_loss: 0.5772\n",
      "Epoch 512/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9176e-04 - val_loss: 0.5620\n",
      "Epoch 513/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7395e-04 - val_loss: 0.5712\n",
      "Epoch 514/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7400e-04 - val_loss: 0.5636\n",
      "Epoch 515/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5225e-04 - val_loss: 0.5700\n",
      "Epoch 516/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5587e-04 - val_loss: 0.5672\n",
      "Epoch 517/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8957e-04 - val_loss: 0.5641\n",
      "Epoch 518/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7481e-04 - val_loss: 0.5694\n",
      "Epoch 519/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0769e-04 - val_loss: 0.5701\n",
      "Epoch 520/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0112e-04 - val_loss: 0.5707\n",
      "Epoch 521/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0555e-04 - val_loss: 0.5738\n",
      "Epoch 522/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1063e-04 - val_loss: 0.5652\n",
      "Epoch 523/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3313e-04 - val_loss: 0.5880\n",
      "Epoch 524/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0301e-04 - val_loss: 0.5658\n",
      "Epoch 525/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9734e-04 - val_loss: 0.5847\n",
      "Epoch 526/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5180e-04 - val_loss: 0.5653\n",
      "Epoch 527/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.1943e-04 - val_loss: 0.5775\n",
      "Epoch 528/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6219e-04 - val_loss: 0.5634\n",
      "Epoch 529/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3562e-04 - val_loss: 0.5861\n",
      "Epoch 530/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8011e-04 - val_loss: 0.5704\n",
      "Epoch 531/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1501e-04 - val_loss: 0.5669\n",
      "Epoch 532/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4333e-04 - val_loss: 0.5810\n",
      "Epoch 533/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0775e-04 - val_loss: 0.5811\n",
      "Epoch 534/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2076e-04 - val_loss: 0.5839\n",
      "Epoch 535/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1255e-04 - val_loss: 0.5772\n",
      "Epoch 536/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0806e-04 - val_loss: 0.5834\n",
      "Epoch 537/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6807e-04 - val_loss: 0.5823\n",
      "Epoch 538/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6456e-04 - val_loss: 0.5893\n",
      "Epoch 539/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8855e-04 - val_loss: 0.5859\n",
      "Epoch 540/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3637e-04 - val_loss: 0.5863\n",
      "Epoch 541/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3282e-04 - val_loss: 0.5856\n",
      "Epoch 542/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2269e-04 - val_loss: 0.5878\n",
      "Epoch 543/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3346e-04 - val_loss: 0.5908\n",
      "Epoch 544/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3728e-04 - val_loss: 0.5910\n",
      "Epoch 545/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0454e-04 - val_loss: 0.5943\n",
      "Epoch 546/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5467e-04 - val_loss: 0.5879\n",
      "Epoch 547/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4377e-04 - val_loss: 0.5844\n",
      "Epoch 548/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6474e-04 - val_loss: 0.5854\n",
      "Epoch 549/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5218e-04 - val_loss: 0.5872\n",
      "Epoch 550/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1758e-04 - val_loss: 0.5814\n",
      "Epoch 551/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9310e-04 - val_loss: 0.5932\n",
      "Epoch 552/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7883e-04 - val_loss: 0.5931\n",
      "Epoch 553/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0472e-04 - val_loss: 0.5966\n",
      "Epoch 554/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0339e-04 - val_loss: 0.5997\n",
      "Epoch 555/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8343e-04 - val_loss: 0.5927\n",
      "Epoch 556/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8672e-04 - val_loss: 0.5968\n",
      "Epoch 557/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7374e-04 - val_loss: 0.5959\n",
      "Epoch 558/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.2033e-04 - val_loss: 0.5958\n",
      "Epoch 559/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1143e-04 - val_loss: 0.5941\n",
      "Epoch 560/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7794e-04 - val_loss: 0.6010\n",
      "Epoch 561/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4915e-04 - val_loss: 0.6010\n",
      "Epoch 562/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8912e-04 - val_loss: 0.5973\n",
      "Epoch 563/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5536e-04 - val_loss: 0.6043\n",
      "Epoch 564/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6058e-04 - val_loss: 0.6006\n",
      "Epoch 565/700\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.7427e-04 - val_loss: 0.6097\n",
      "Epoch 566/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.4759e-04 - val_loss: 0.6016\n",
      "Epoch 567/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2776e-04 - val_loss: 0.6085\n",
      "Epoch 568/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2561e-04 - val_loss: 0.5992\n",
      "Epoch 569/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7827e-04 - val_loss: 0.6087\n",
      "Epoch 570/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7941e-04 - val_loss: 0.6013\n",
      "Epoch 571/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4286e-04 - val_loss: 0.6012\n",
      "Epoch 572/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5826e-04 - val_loss: 0.6068\n",
      "Epoch 573/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3900e-04 - val_loss: 0.6077\n",
      "Epoch 574/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0687e-04 - val_loss: 0.6054\n",
      "Epoch 575/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3062e-04 - val_loss: 0.6118\n",
      "Epoch 576/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0504e-04 - val_loss: 0.6035\n",
      "Epoch 577/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.0686e-04 - val_loss: 0.6107\n",
      "Epoch 578/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.8675e-04 - val_loss: 0.6114\n",
      "Epoch 579/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8221e-04 - val_loss: 0.6130\n",
      "Epoch 580/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8867e-04 - val_loss: 0.6105\n",
      "Epoch 581/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0297e-04 - val_loss: 0.6164\n",
      "Epoch 582/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1199e-04 - val_loss: 0.6177\n",
      "Epoch 583/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5825e-04 - val_loss: 0.6130\n",
      "Epoch 584/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8346e-04 - val_loss: 0.6216\n",
      "Epoch 585/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7558e-04 - val_loss: 0.6174\n",
      "Epoch 586/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.3188e-04 - val_loss: 0.6197\n",
      "Epoch 587/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.8476e-04 - val_loss: 0.6212\n",
      "Epoch 588/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.6389e-04 - val_loss: 0.6178\n",
      "Epoch 589/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.4493e-04 - val_loss: 0.6275\n",
      "Epoch 590/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.7929e-04 - val_loss: 0.6201\n",
      "Epoch 591/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.5188e-04 - val_loss: 0.6189\n",
      "Epoch 592/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.4747e-04 - val_loss: 0.6205\n",
      "Epoch 593/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.5391e-04 - val_loss: 0.6229\n",
      "Epoch 594/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.3672e-04 - val_loss: 0.6259\n",
      "Epoch 595/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3735e-04 - val_loss: 0.6261\n",
      "Epoch 596/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.6539e-04 - val_loss: 0.6258\n",
      "Epoch 597/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.3824e-04 - val_loss: 0.6275\n",
      "Epoch 598/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7138e-04 - val_loss: 0.6300\n",
      "Epoch 599/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5979e-04 - val_loss: 0.6336\n",
      "Epoch 600/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1418e-04 - val_loss: 0.6246\n",
      "Epoch 601/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4290e-04 - val_loss: 0.6337\n",
      "Epoch 602/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2246e-04 - val_loss: 0.6307\n",
      "Epoch 603/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5074e-04 - val_loss: 0.6286\n",
      "Epoch 604/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3102e-04 - val_loss: 0.6338\n",
      "Epoch 605/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3029e-04 - val_loss: 0.6307\n",
      "Epoch 606/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.0651e-04 - val_loss: 0.6379\n",
      "Epoch 607/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.3098e-04 - val_loss: 0.6379\n",
      "Epoch 608/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8552e-04 - val_loss: 0.6273\n",
      "Epoch 609/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2408e-04 - val_loss: 0.6444\n",
      "Epoch 610/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4548e-04 - val_loss: 0.6306\n",
      "Epoch 611/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8561e-04 - val_loss: 0.6350\n",
      "Epoch 612/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1777e-04 - val_loss: 0.6405\n",
      "Epoch 613/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2628e-04 - val_loss: 0.6541\n",
      "Epoch 614/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9882e-04 - val_loss: 0.6299\n",
      "Epoch 615/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5144e-04 - val_loss: 0.6408\n",
      "Epoch 616/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8694e-04 - val_loss: 0.6392\n",
      "Epoch 617/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8227e-04 - val_loss: 0.6370\n",
      "Epoch 618/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6706e-04 - val_loss: 0.6396\n",
      "Epoch 619/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7176e-04 - val_loss: 0.6381\n",
      "Epoch 620/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6553e-04 - val_loss: 0.6431\n",
      "Epoch 621/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6631e-04 - val_loss: 0.6435\n",
      "Epoch 622/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6179e-04 - val_loss: 0.6425\n",
      "Epoch 623/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6594e-04 - val_loss: 0.6415\n",
      "Epoch 624/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7900e-04 - val_loss: 0.6447\n",
      "Epoch 625/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6985e-04 - val_loss: 0.6469\n",
      "Epoch 626/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5684e-04 - val_loss: 0.6392\n",
      "Epoch 627/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5279e-04 - val_loss: 0.6409\n",
      "Epoch 628/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5769e-04 - val_loss: 0.6389\n",
      "Epoch 629/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7882e-04 - val_loss: 0.6384\n",
      "Epoch 630/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.4668e-04 - val_loss: 0.6398\n",
      "Epoch 631/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3382e-04 - val_loss: 0.6390\n",
      "Epoch 632/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.4262e-04 - val_loss: 0.6418\n",
      "Epoch 633/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3535e-04 - val_loss: 0.6416\n",
      "Epoch 634/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3943e-04 - val_loss: 0.6429\n",
      "Epoch 635/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2670e-04 - val_loss: 0.6403\n",
      "Epoch 636/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3222e-04 - val_loss: 0.6424\n",
      "Epoch 637/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2520e-04 - val_loss: 0.6444\n",
      "Epoch 638/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3560e-04 - val_loss: 0.6419\n",
      "Epoch 639/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3468e-04 - val_loss: 0.6410\n",
      "Epoch 640/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2303e-04 - val_loss: 0.6457\n",
      "Epoch 641/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2869e-04 - val_loss: 0.6464\n",
      "Epoch 642/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2807e-04 - val_loss: 0.6486\n",
      "Epoch 643/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2321e-04 - val_loss: 0.6504\n",
      "Epoch 644/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0751e-04 - val_loss: 0.6479\n",
      "Epoch 645/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2272e-04 - val_loss: 0.6515\n",
      "Epoch 646/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1271e-04 - val_loss: 0.6519\n",
      "Epoch 647/700\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3908e-04 - val_loss: 0.6499\n",
      "Epoch 648/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2625e-04 - val_loss: 0.6560\n",
      "Epoch 649/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1669e-04 - val_loss: 0.6502\n",
      "Epoch 650/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1069e-04 - val_loss: 0.6579\n",
      "Epoch 651/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9916e-04 - val_loss: 0.6535\n",
      "Epoch 652/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1393e-04 - val_loss: 0.6567\n",
      "Epoch 653/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0973e-04 - val_loss: 0.6574\n",
      "Epoch 654/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0063e-04 - val_loss: 0.6555\n",
      "Epoch 655/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1748e-04 - val_loss: 0.6525\n",
      "Epoch 656/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0851e-04 - val_loss: 0.6630\n",
      "Epoch 657/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0302e-04 - val_loss: 0.6556\n",
      "Epoch 658/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9997e-04 - val_loss: 0.6596\n",
      "Epoch 659/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1614e-04 - val_loss: 0.6607\n",
      "Epoch 660/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0978e-04 - val_loss: 0.6569\n",
      "Epoch 661/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0695e-04 - val_loss: 0.6739\n",
      "Epoch 662/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0409e-04 - val_loss: 0.6625\n",
      "Epoch 663/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5365e-04 - val_loss: 0.6708\n",
      "Epoch 664/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8164e-04 - val_loss: 0.6630\n",
      "Epoch 665/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2954e-04 - val_loss: 0.6627\n",
      "Epoch 666/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9407e-04 - val_loss: 0.6748\n",
      "Epoch 667/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1701e-04 - val_loss: 0.6604\n",
      "Epoch 668/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7509e-04 - val_loss: 0.6650\n",
      "Epoch 669/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9468e-04 - val_loss: 0.6652\n",
      "Epoch 670/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9828e-04 - val_loss: 0.6654\n",
      "Epoch 671/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7650e-04 - val_loss: 0.6704\n",
      "Epoch 672/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7796e-04 - val_loss: 0.6695\n",
      "Epoch 673/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7173e-04 - val_loss: 0.6722\n",
      "Epoch 674/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7635e-04 - val_loss: 0.6729\n",
      "Epoch 675/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6120e-04 - val_loss: 0.6692\n",
      "Epoch 676/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7531e-04 - val_loss: 0.6687\n",
      "Epoch 677/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8734e-04 - val_loss: 0.6778\n",
      "Epoch 678/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6326e-04 - val_loss: 0.6730\n",
      "Epoch 679/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6089e-04 - val_loss: 0.6784\n",
      "Epoch 680/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5830e-04 - val_loss: 0.6779\n",
      "Epoch 681/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6806e-04 - val_loss: 0.6765\n",
      "Epoch 682/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9481e-04 - val_loss: 0.6759\n",
      "Epoch 683/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6991e-04 - val_loss: 0.6824\n",
      "Epoch 684/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7037e-04 - val_loss: 0.6778\n",
      "Epoch 685/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5246e-04 - val_loss: 0.6798\n",
      "Epoch 686/700\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5046e-04 - val_loss: 0.6810\n",
      "Epoch 687/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5033e-04 - val_loss: 0.6808\n",
      "Epoch 688/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8445e-04 - val_loss: 0.6800\n",
      "Epoch 689/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6728e-04 - val_loss: 0.6845\n",
      "Epoch 690/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3475e-04 - val_loss: 0.6740\n",
      "Epoch 691/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8075e-04 - val_loss: 0.6831\n",
      "Epoch 692/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5255e-04 - val_loss: 0.6761\n",
      "Epoch 693/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6581e-04 - val_loss: 0.6797\n",
      "Epoch 694/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5158e-04 - val_loss: 0.6845\n",
      "Epoch 695/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5692e-04 - val_loss: 0.6811\n",
      "Epoch 696/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3744e-04 - val_loss: 0.6821\n",
      "Epoch 697/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4474e-04 - val_loss: 0.6830\n",
      "Epoch 698/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4067e-04 - val_loss: 0.6854\n",
      "Epoch 699/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3728e-04 - val_loss: 0.6849\n",
      "Epoch 700/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4355e-04 - val_loss: 0.6861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23bc7bb6940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() # model oluşturuyoruz\n",
    "model.add(Dense(units=30,activation=\"relu\")) # içeriğe 30 tane nöron koy, genelde de kolon sayısı kadar nöron koyulur.\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dense(units=1,activation=\"sigmoid\")) #sınıflandırma problemlerinde sigmoid kullanılır çünkü çıkışları 1 veya 0'dır\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "# epochs hep 200-300 gibi bir değerdi. Kaç kere veriyi işleyeceğini gösteriyor.\n",
    "model.fit(x=x_train, y=y_train, epochs=700,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33687879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6739331483840942,\n",
       "  0.6493321657180786,\n",
       "  0.619185745716095,\n",
       "  0.5837774276733398,\n",
       "  0.5427794456481934,\n",
       "  0.4943355619907379,\n",
       "  0.4442936182022095,\n",
       "  0.397479772567749,\n",
       "  0.356316477060318,\n",
       "  0.32325637340545654,\n",
       "  0.2874663770198822,\n",
       "  0.2586055099964142,\n",
       "  0.23258334398269653,\n",
       "  0.2106766253709793,\n",
       "  0.19603313505649567,\n",
       "  0.18149811029434204,\n",
       "  0.17018534243106842,\n",
       "  0.15821780264377594,\n",
       "  0.1550569236278534,\n",
       "  0.14659610390663147,\n",
       "  0.13632096350193024,\n",
       "  0.13793888688087463,\n",
       "  0.13213756680488586,\n",
       "  0.12803028523921967,\n",
       "  0.12503212690353394,\n",
       "  0.12386161834001541,\n",
       "  0.11293727904558182,\n",
       "  0.1155269593000412,\n",
       "  0.11299441754817963,\n",
       "  0.11131460964679718,\n",
       "  0.10640574991703033,\n",
       "  0.10218854993581772,\n",
       "  0.10046986490488052,\n",
       "  0.09935597330331802,\n",
       "  0.09692278504371643,\n",
       "  0.09529456496238708,\n",
       "  0.09361468255519867,\n",
       "  0.0915839895606041,\n",
       "  0.09062569588422775,\n",
       "  0.09021685272455215,\n",
       "  0.09285089373588562,\n",
       "  0.09753678739070892,\n",
       "  0.08803670108318329,\n",
       "  0.08563265949487686,\n",
       "  0.08618038892745972,\n",
       "  0.08214370906352997,\n",
       "  0.08313790708780289,\n",
       "  0.08246438950300217,\n",
       "  0.08004331588745117,\n",
       "  0.0784720778465271,\n",
       "  0.07736440002918243,\n",
       "  0.07797986268997192,\n",
       "  0.07911310344934464,\n",
       "  0.07630591094493866,\n",
       "  0.07509922981262207,\n",
       "  0.07423879951238632,\n",
       "  0.0735592395067215,\n",
       "  0.07487333565950394,\n",
       "  0.07423191517591476,\n",
       "  0.07371801137924194,\n",
       "  0.07409287989139557,\n",
       "  0.06993680447340012,\n",
       "  0.07114274799823761,\n",
       "  0.06927142292261124,\n",
       "  0.06996939331293106,\n",
       "  0.07152826339006424,\n",
       "  0.06718559563159943,\n",
       "  0.06859514117240906,\n",
       "  0.07042267173528671,\n",
       "  0.06749780476093292,\n",
       "  0.06596552580595016,\n",
       "  0.0700538232922554,\n",
       "  0.06644954532384872,\n",
       "  0.06470103561878204,\n",
       "  0.06526511907577515,\n",
       "  0.06700872629880905,\n",
       "  0.06254156678915024,\n",
       "  0.06358249485492706,\n",
       "  0.06437086313962936,\n",
       "  0.0649770125746727,\n",
       "  0.061323635280132294,\n",
       "  0.06455403566360474,\n",
       "  0.06226014345884323,\n",
       "  0.06383754312992096,\n",
       "  0.063604936003685,\n",
       "  0.062031857669353485,\n",
       "  0.05929000675678253,\n",
       "  0.05990488454699516,\n",
       "  0.060135334730148315,\n",
       "  0.059234023094177246,\n",
       "  0.05824452266097069,\n",
       "  0.05855406075716019,\n",
       "  0.055861834436655045,\n",
       "  0.05748810991644859,\n",
       "  0.057967886328697205,\n",
       "  0.05581578239798546,\n",
       "  0.055581096559762955,\n",
       "  0.057321324944496155,\n",
       "  0.055705033242702484,\n",
       "  0.05583418905735016,\n",
       "  0.054781053215265274,\n",
       "  0.05417325720191002,\n",
       "  0.05529377609491348,\n",
       "  0.053761642426252365,\n",
       "  0.05481591448187828,\n",
       "  0.05555279552936554,\n",
       "  0.055608708411455154,\n",
       "  0.05320179834961891,\n",
       "  0.053191330283880234,\n",
       "  0.053537920117378235,\n",
       "  0.05656583607196808,\n",
       "  0.05140437185764313,\n",
       "  0.05063501000404358,\n",
       "  0.05931564420461655,\n",
       "  0.0625087097287178,\n",
       "  0.05478309094905853,\n",
       "  0.053804896771907806,\n",
       "  0.05129110440611839,\n",
       "  0.05024272948503494,\n",
       "  0.04984702169895172,\n",
       "  0.05070905014872551,\n",
       "  0.04884437099099159,\n",
       "  0.04944736510515213,\n",
       "  0.04637761414051056,\n",
       "  0.04967889189720154,\n",
       "  0.05002514645457268,\n",
       "  0.046451009809970856,\n",
       "  0.04684531316161156,\n",
       "  0.04517079517245293,\n",
       "  0.04777054861187935,\n",
       "  0.048885758966207504,\n",
       "  0.04940436780452728,\n",
       "  0.04788070544600487,\n",
       "  0.04802968353033066,\n",
       "  0.04430244490504265,\n",
       "  0.04460565373301506,\n",
       "  0.04288391396403313,\n",
       "  0.042081527411937714,\n",
       "  0.04628700762987137,\n",
       "  0.04803379997611046,\n",
       "  0.0438712053000927,\n",
       "  0.04111192747950554,\n",
       "  0.0446854829788208,\n",
       "  0.040226660668849945,\n",
       "  0.047722868621349335,\n",
       "  0.04589851200580597,\n",
       "  0.04020412638783455,\n",
       "  0.04159637913107872,\n",
       "  0.0384005531668663,\n",
       "  0.044160254299640656,\n",
       "  0.05090261250734329,\n",
       "  0.05702805146574974,\n",
       "  0.03852180764079094,\n",
       "  0.03990675508975983,\n",
       "  0.0404646135866642,\n",
       "  0.03935423493385315,\n",
       "  0.03915896639227867,\n",
       "  0.03728766739368439,\n",
       "  0.038179680705070496,\n",
       "  0.03987429663538933,\n",
       "  0.040180958807468414,\n",
       "  0.035741254687309265,\n",
       "  0.03885594382882118,\n",
       "  0.04533682018518448,\n",
       "  0.039848826825618744,\n",
       "  0.04862522706389427,\n",
       "  0.03583836182951927,\n",
       "  0.03980961814522743,\n",
       "  0.03492208942770958,\n",
       "  0.037512339651584625,\n",
       "  0.03539348393678665,\n",
       "  0.033432092517614365,\n",
       "  0.035607192665338516,\n",
       "  0.042162030935287476,\n",
       "  0.04621699079871178,\n",
       "  0.034516479820013046,\n",
       "  0.03316722810268402,\n",
       "  0.03307237848639488,\n",
       "  0.03490239381790161,\n",
       "  0.031106341630220413,\n",
       "  0.031823500990867615,\n",
       "  0.03200538828969002,\n",
       "  0.03057076781988144,\n",
       "  0.030793389305472374,\n",
       "  0.03488524630665779,\n",
       "  0.033154215663671494,\n",
       "  0.03167806938290596,\n",
       "  0.030139610171318054,\n",
       "  0.02831982634961605,\n",
       "  0.03269728645682335,\n",
       "  0.03260384872555733,\n",
       "  0.030668945983052254,\n",
       "  0.03343052789568901,\n",
       "  0.03053813800215721,\n",
       "  0.02881687879562378,\n",
       "  0.03041754849255085,\n",
       "  0.027392741292715073,\n",
       "  0.029653919860720634,\n",
       "  0.0301760733127594,\n",
       "  0.02781064249575138,\n",
       "  0.02608095109462738,\n",
       "  0.027816995978355408,\n",
       "  0.026679476723074913,\n",
       "  0.025028450414538383,\n",
       "  0.02655862644314766,\n",
       "  0.02706220932304859,\n",
       "  0.02828381210565567,\n",
       "  0.02417057752609253,\n",
       "  0.02517637610435486,\n",
       "  0.027469130232930183,\n",
       "  0.025144141167402267,\n",
       "  0.023602329194545746,\n",
       "  0.02413649670779705,\n",
       "  0.024337412789463997,\n",
       "  0.025772087275981903,\n",
       "  0.023182028904557228,\n",
       "  0.023705732077360153,\n",
       "  0.02383207157254219,\n",
       "  0.023141300305724144,\n",
       "  0.024966541677713394,\n",
       "  0.023113323375582695,\n",
       "  0.02394435927271843,\n",
       "  0.022677453234791756,\n",
       "  0.021456435322761536,\n",
       "  0.024017350748181343,\n",
       "  0.021110935136675835,\n",
       "  0.021045401692390442,\n",
       "  0.021716903895139694,\n",
       "  0.02171974815428257,\n",
       "  0.021435251459479332,\n",
       "  0.025992143899202347,\n",
       "  0.02326597087085247,\n",
       "  0.022716261446475983,\n",
       "  0.023910995572805405,\n",
       "  0.01952921226620674,\n",
       "  0.02018454112112522,\n",
       "  0.020140882581472397,\n",
       "  0.018611513078212738,\n",
       "  0.019348671659827232,\n",
       "  0.019854074344038963,\n",
       "  0.01866273581981659,\n",
       "  0.02043832838535309,\n",
       "  0.020968059077858925,\n",
       "  0.023658448830246925,\n",
       "  0.018130071461200714,\n",
       "  0.017888126894831657,\n",
       "  0.02031109854578972,\n",
       "  0.01624748855829239,\n",
       "  0.01679006591439247,\n",
       "  0.016328001394867897,\n",
       "  0.016837839037179947,\n",
       "  0.018148697912693024,\n",
       "  0.015530822798609734,\n",
       "  0.016231168061494827,\n",
       "  0.016721805557608604,\n",
       "  0.021144846454262733,\n",
       "  0.01987726241350174,\n",
       "  0.014450417831540108,\n",
       "  0.01579080894589424,\n",
       "  0.015211411751806736,\n",
       "  0.016516659408807755,\n",
       "  0.014042810536921024,\n",
       "  0.014462037943303585,\n",
       "  0.015542633831501007,\n",
       "  0.015796639025211334,\n",
       "  0.014588645659387112,\n",
       "  0.01413978636264801,\n",
       "  0.015357951633632183,\n",
       "  0.01588716171681881,\n",
       "  0.014561653137207031,\n",
       "  0.013616584241390228,\n",
       "  0.01407773420214653,\n",
       "  0.013127771206200123,\n",
       "  0.013305161148309708,\n",
       "  0.01352511253207922,\n",
       "  0.012054162099957466,\n",
       "  0.01375878881663084,\n",
       "  0.014727252535521984,\n",
       "  0.012393548153340816,\n",
       "  0.012225838378071785,\n",
       "  0.011623834259808064,\n",
       "  0.011995648965239525,\n",
       "  0.015193535946309566,\n",
       "  0.017140252515673637,\n",
       "  0.01769695058465004,\n",
       "  0.014845599420368671,\n",
       "  0.010813746601343155,\n",
       "  0.010963675566017628,\n",
       "  0.011337582021951675,\n",
       "  0.013414045795798302,\n",
       "  0.013650989159941673,\n",
       "  0.013495230115950108,\n",
       "  0.016970055177807808,\n",
       "  0.013474568724632263,\n",
       "  0.012671448290348053,\n",
       "  0.010952568612992764,\n",
       "  0.010234844870865345,\n",
       "  0.009293944574892521,\n",
       "  0.009256996214389801,\n",
       "  0.010427475906908512,\n",
       "  0.010888423770666122,\n",
       "  0.009519526734948158,\n",
       "  0.009098928421735764,\n",
       "  0.008676313795149326,\n",
       "  0.008712505921721458,\n",
       "  0.008848925121128559,\n",
       "  0.008785447105765343,\n",
       "  0.009147962555289268,\n",
       "  0.008188920095562935,\n",
       "  0.008137846365571022,\n",
       "  0.007905598729848862,\n",
       "  0.009527305141091347,\n",
       "  0.010504045523703098,\n",
       "  0.011145624332129955,\n",
       "  0.007510886061936617,\n",
       "  0.008303484879434109,\n",
       "  0.008246737532317638,\n",
       "  0.00916297547519207,\n",
       "  0.00833632331341505,\n",
       "  0.00741599453613162,\n",
       "  0.011315167881548405,\n",
       "  0.009610231965780258,\n",
       "  0.007099682465195656,\n",
       "  0.007059392984956503,\n",
       "  0.0068152472376823425,\n",
       "  0.006844993680715561,\n",
       "  0.009296727366745472,\n",
       "  0.008649786002933979,\n",
       "  0.006384712643921375,\n",
       "  0.006541818846017122,\n",
       "  0.006412626709789038,\n",
       "  0.005991971120238304,\n",
       "  0.006429628469049931,\n",
       "  0.0070783598348498344,\n",
       "  0.006271348800510168,\n",
       "  0.0066186198964715,\n",
       "  0.005458755884319544,\n",
       "  0.005598391871899366,\n",
       "  0.005907156970351934,\n",
       "  0.005405004136264324,\n",
       "  0.0052084047347307205,\n",
       "  0.005879868287593126,\n",
       "  0.005852934438735247,\n",
       "  0.005816182121634483,\n",
       "  0.005453621502965689,\n",
       "  0.005107271485030651,\n",
       "  0.0048285978846251965,\n",
       "  0.0053206621669232845,\n",
       "  0.004690408241003752,\n",
       "  0.004692327231168747,\n",
       "  0.004697529599070549,\n",
       "  0.005126598756760359,\n",
       "  0.005557012744247913,\n",
       "  0.005522481631487608,\n",
       "  0.004322883207350969,\n",
       "  0.005340404808521271,\n",
       "  0.005753908772021532,\n",
       "  0.005728559568524361,\n",
       "  0.01038304902613163,\n",
       "  0.009199533611536026,\n",
       "  0.0072198412381112576,\n",
       "  0.004109247587621212,\n",
       "  0.004347431007772684,\n",
       "  0.00483212573453784,\n",
       "  0.0049196346662938595,\n",
       "  0.003963716793805361,\n",
       "  0.003589966567233205,\n",
       "  0.0036314022727310658,\n",
       "  0.003996245097368956,\n",
       "  0.006060088984668255,\n",
       "  0.0057994285598397255,\n",
       "  0.003927331883460283,\n",
       "  0.0036893091164529324,\n",
       "  0.003476712154224515,\n",
       "  0.0036847186274826527,\n",
       "  0.003269700799137354,\n",
       "  0.003229941474273801,\n",
       "  0.003114576218649745,\n",
       "  0.003109666984528303,\n",
       "  0.003448758041486144,\n",
       "  0.0036211872939020395,\n",
       "  0.004274304956197739,\n",
       "  0.00408029044046998,\n",
       "  0.0030042531434446573,\n",
       "  0.00309079815633595,\n",
       "  0.0029340849723666906,\n",
       "  0.002801587339490652,\n",
       "  0.0031252228654921055,\n",
       "  0.0028763797599822283,\n",
       "  0.0029506722930818796,\n",
       "  0.003456489648669958,\n",
       "  0.004456425551325083,\n",
       "  0.004345068242400885,\n",
       "  0.00591514864936471,\n",
       "  0.004194906447082758,\n",
       "  0.0035584496799856424,\n",
       "  0.002718213712796569,\n",
       "  0.0027269022539258003,\n",
       "  0.0026564188301563263,\n",
       "  0.0028720973059535027,\n",
       "  0.0021326092537492514,\n",
       "  0.002478513168171048,\n",
       "  0.0026781626511365175,\n",
       "  0.002373896772041917,\n",
       "  0.002188983606174588,\n",
       "  0.0022472168784588575,\n",
       "  0.002381791826337576,\n",
       "  0.0021088551729917526,\n",
       "  0.0020639835856854916,\n",
       "  0.0020701459143310785,\n",
       "  0.0020781373605132103,\n",
       "  0.002065816894173622,\n",
       "  0.0021783073898404837,\n",
       "  0.0026152576319873333,\n",
       "  0.0026181568391621113,\n",
       "  0.002168847480788827,\n",
       "  0.002077882643789053,\n",
       "  0.002168611390516162,\n",
       "  0.0022685674484819174,\n",
       "  0.002788203302770853,\n",
       "  0.0029613119550049305,\n",
       "  0.0027760020457208157,\n",
       "  0.0020305386278778315,\n",
       "  0.0018487516790628433,\n",
       "  0.0018013184890151024,\n",
       "  0.0022331608925014734,\n",
       "  0.0030393656343221664,\n",
       "  0.0027574030682444572,\n",
       "  0.0020944473799318075,\n",
       "  0.0015690004220232368,\n",
       "  0.001678295317105949,\n",
       "  0.0017022319370880723,\n",
       "  0.0015670227585360408,\n",
       "  0.0017180964350700378,\n",
       "  0.0016347725177183747,\n",
       "  0.0016279129777103662,\n",
       "  0.0015646856045350432,\n",
       "  0.001494976575486362,\n",
       "  0.0014730441616848111,\n",
       "  0.001542986836284399,\n",
       "  0.0015600972110405564,\n",
       "  0.0014274546410888433,\n",
       "  0.00147565349470824,\n",
       "  0.0019013391574844718,\n",
       "  0.0018377361120656133,\n",
       "  0.0017752369167283177,\n",
       "  0.0014059098903089762,\n",
       "  0.0015384417492896318,\n",
       "  0.0013694227673113346,\n",
       "  0.0013659652322530746,\n",
       "  0.001458860351704061,\n",
       "  0.0013664605794474483,\n",
       "  0.0013005711371079087,\n",
       "  0.0014709020033478737,\n",
       "  0.001509030582383275,\n",
       "  0.0017756437882781029,\n",
       "  0.0014660560991615057,\n",
       "  0.0012326516443863511,\n",
       "  0.0012557350564748049,\n",
       "  0.0017012880416586995,\n",
       "  0.0013467638054862618,\n",
       "  0.0014082039706408978,\n",
       "  0.0017758059548214078,\n",
       "  0.0014892921317368746,\n",
       "  0.0011703502386808395,\n",
       "  0.0011452495818957686,\n",
       "  0.0011472597252577543,\n",
       "  0.0010692108189687133,\n",
       "  0.0011355236638337374,\n",
       "  0.0010987137211486697,\n",
       "  0.0011463172268122435,\n",
       "  0.0010958962375298142,\n",
       "  0.0009961235336959362,\n",
       "  0.0010309548815712333,\n",
       "  0.0009778218809515238,\n",
       "  0.0010144769912585616,\n",
       "  0.0009857333498075604,\n",
       "  0.0011731357080861926,\n",
       "  0.001134232385084033,\n",
       "  0.0009938899893313646,\n",
       "  0.0010349019430577755,\n",
       "  0.0009445720934309065,\n",
       "  0.0010185347637161613,\n",
       "  0.0010849894024431705,\n",
       "  0.001132236560806632,\n",
       "  0.0010194844799116254,\n",
       "  0.0009298892691731453,\n",
       "  0.0011256795842200518,\n",
       "  0.0009253505850210786,\n",
       "  0.0008708871901035309,\n",
       "  0.0008692711126059294,\n",
       "  0.0008593357051722705,\n",
       "  0.0008416869677603245,\n",
       "  0.0008267599041573703,\n",
       "  0.0008807817357592285,\n",
       "  0.0008455071365460753,\n",
       "  0.0009330918546766043,\n",
       "  0.0008471778710372746,\n",
       "  0.0008293427526950836,\n",
       "  0.0007650133338756859,\n",
       "  0.0008810939616523683,\n",
       "  0.000907336943782866,\n",
       "  0.0008134030504152179,\n",
       "  0.0007726416224613786,\n",
       "  0.000798362132627517,\n",
       "  0.0007975349435582757,\n",
       "  0.0008210375090129673,\n",
       "  0.0007710732170380652,\n",
       "  0.0007315881666727364,\n",
       "  0.0008768904372118413,\n",
       "  0.0008222768665291369,\n",
       "  0.0006917625432834029,\n",
       "  0.0007739529828540981,\n",
       "  0.0006740004755556583,\n",
       "  0.0007522545056417584,\n",
       "  0.0009558730525895953,\n",
       "  0.0007895677117630839,\n",
       "  0.0006748079904355109,\n",
       "  0.0007076936308294535,\n",
       "  0.0008011243771761656,\n",
       "  0.0007055489695630968,\n",
       "  0.0007106268312782049,\n",
       "  0.0008331285207532346,\n",
       "  0.0007030130364000797,\n",
       "  0.0007973355241119862,\n",
       "  0.0007518014754168689,\n",
       "  0.0009194299927912652,\n",
       "  0.0007621936383657157,\n",
       "  0.0006356188096106052,\n",
       "  0.0006801062845624983,\n",
       "  0.0006150070112198591,\n",
       "  0.0006433305097743869,\n",
       "  0.0007077513146214187,\n",
       "  0.000720759155228734,\n",
       "  0.0006125454674474895,\n",
       "  0.0007080630166456103,\n",
       "  0.0005680699832737446,\n",
       "  0.0005645636119879782,\n",
       "  0.0005885528516955674,\n",
       "  0.0005363650852814317,\n",
       "  0.0005328235565684736,\n",
       "  0.0005226898938417435,\n",
       "  0.0005334570887498558,\n",
       "  0.0005372785381041467,\n",
       "  0.0005045444122515619,\n",
       "  0.0005546655738726258,\n",
       "  0.0006437716074287891,\n",
       "  0.0006647350965067744,\n",
       "  0.0006521804607473314,\n",
       "  0.0005175824044272304,\n",
       "  0.0004931020084768534,\n",
       "  0.0004788306832779199,\n",
       "  0.0005047174054197967,\n",
       "  0.0005033898632973433,\n",
       "  0.0004834327264688909,\n",
       "  0.0004867216048296541,\n",
       "  0.00047373579582199454,\n",
       "  0.0005203292239457369,\n",
       "  0.0005114332307130098,\n",
       "  0.00047794150304980576,\n",
       "  0.00044915181933902204,\n",
       "  0.0004891229909844697,\n",
       "  0.0004553647304419428,\n",
       "  0.0004605782451108098,\n",
       "  0.0004742743039969355,\n",
       "  0.00044758885633200407,\n",
       "  0.00042776085319928825,\n",
       "  0.0004256110405549407,\n",
       "  0.0004782698815688491,\n",
       "  0.0005794111639261246,\n",
       "  0.0004428648971952498,\n",
       "  0.00045826000859960914,\n",
       "  0.00043900401215068996,\n",
       "  0.0004068712005391717,\n",
       "  0.000430622894782573,\n",
       "  0.00040504051139578223,\n",
       "  0.00040685999556444585,\n",
       "  0.0003867517807520926,\n",
       "  0.00038221338763833046,\n",
       "  0.00038866951945237815,\n",
       "  0.0004029712872579694,\n",
       "  0.00041199190309271216,\n",
       "  0.0003582504577934742,\n",
       "  0.0003834595554508269,\n",
       "  0.0003755792276933789,\n",
       "  0.0004318782011978328,\n",
       "  0.0003847576736006886,\n",
       "  0.0003638899652287364,\n",
       "  0.0004449266998562962,\n",
       "  0.00037928548408672214,\n",
       "  0.0003518832672853023,\n",
       "  0.00034746999153867364,\n",
       "  0.00035390545963309705,\n",
       "  0.00033671865821816027,\n",
       "  0.00033734948374331,\n",
       "  0.00036538694985210896,\n",
       "  0.00033823776175267994,\n",
       "  0.0003713752084877342,\n",
       "  0.0003597889153752476,\n",
       "  0.00031418033177033067,\n",
       "  0.0003428975469432771,\n",
       "  0.00032245952752418816,\n",
       "  0.00035073651815764606,\n",
       "  0.00033101634471677244,\n",
       "  0.0003302943950984627,\n",
       "  0.000306507310597226,\n",
       "  0.000330975599354133,\n",
       "  0.00028551911236718297,\n",
       "  0.0003240799414925277,\n",
       "  0.000345478329109028,\n",
       "  0.00038561131805181503,\n",
       "  0.00041777428123168647,\n",
       "  0.0006262804963625968,\n",
       "  0.0004988185246475041,\n",
       "  0.0003514356794767082,\n",
       "  0.00028694470529444516,\n",
       "  0.0002822723181452602,\n",
       "  0.00026705581694841385,\n",
       "  0.00027175983996130526,\n",
       "  0.0002655315038282424,\n",
       "  0.00026631151558831334,\n",
       "  0.0002617895370349288,\n",
       "  0.0002659403835423291,\n",
       "  0.00027899816632270813,\n",
       "  0.0002698458556551486,\n",
       "  0.00025684130378067493,\n",
       "  0.0002527899050619453,\n",
       "  0.00025769436615519226,\n",
       "  0.0002788163546938449,\n",
       "  0.0002466781879775226,\n",
       "  0.00023381908249575645,\n",
       "  0.00024261635553557426,\n",
       "  0.00023534962383564562,\n",
       "  0.00023943324049469084,\n",
       "  0.00022670273028779775,\n",
       "  0.00023222349409479648,\n",
       "  0.00022519953199662268,\n",
       "  0.00023559624969493598,\n",
       "  0.00023468220024369657,\n",
       "  0.0002230322133982554,\n",
       "  0.00022869449458085,\n",
       "  0.00022806668130215257,\n",
       "  0.00022321476717479527,\n",
       "  0.0002075133379548788,\n",
       "  0.00022272435307968408,\n",
       "  0.00021270755678415298,\n",
       "  0.0002390789013588801,\n",
       "  0.00022624536359217018,\n",
       "  0.00021669198758900166,\n",
       "  0.00021069277136120945,\n",
       "  0.00019916445307899266,\n",
       "  0.000213931969483383,\n",
       "  0.00020972956554032862,\n",
       "  0.0002006309077842161,\n",
       "  0.00021748346625827253,\n",
       "  0.00020851028966717422,\n",
       "  0.00020301654876675457,\n",
       "  0.0001999739761231467,\n",
       "  0.0002161388547392562,\n",
       "  0.00020978445536457002,\n",
       "  0.0002069486363325268,\n",
       "  0.00020408716227393597,\n",
       "  0.0002536522806622088,\n",
       "  0.00018164234643336385,\n",
       "  0.00022953837469685823,\n",
       "  0.00019406568026170135,\n",
       "  0.0002170117513742298,\n",
       "  0.000175091641722247,\n",
       "  0.00019468105165287852,\n",
       "  0.0001982798712560907,\n",
       "  0.00017649632354732603,\n",
       "  0.00017795675375964493,\n",
       "  0.00017172687512356788,\n",
       "  0.00017635094991419464,\n",
       "  0.00016119898646138608,\n",
       "  0.0001753117103362456,\n",
       "  0.0001873436849564314,\n",
       "  0.00016326001787092537,\n",
       "  0.00016088633856270462,\n",
       "  0.00015830299525987357,\n",
       "  0.0001680583372944966,\n",
       "  0.00019480945775285363,\n",
       "  0.00016990742005873471,\n",
       "  0.00017036861390806735,\n",
       "  0.00015246352995745838,\n",
       "  0.0001504612882854417,\n",
       "  0.00015032694500405341,\n",
       "  0.0001844501675805077,\n",
       "  0.0001672846992732957,\n",
       "  0.00013474933803081512,\n",
       "  0.00018074503168463707,\n",
       "  0.00015255155449267477,\n",
       "  0.00016580562805756927,\n",
       "  0.00015158472524490207,\n",
       "  0.00015692299348302186,\n",
       "  0.00013743957970291376,\n",
       "  0.00014474173076450825,\n",
       "  0.0001406740484526381,\n",
       "  0.00013727793702855706,\n",
       "  0.000143550438224338],\n",
       " 'val_loss': [0.6670844554901123,\n",
       "  0.648032009601593,\n",
       "  0.6199286580085754,\n",
       "  0.5928776264190674,\n",
       "  0.5555049777030945,\n",
       "  0.5123887658119202,\n",
       "  0.4743198752403259,\n",
       "  0.4410519301891327,\n",
       "  0.4082068204879761,\n",
       "  0.37708666920661926,\n",
       "  0.3645090162754059,\n",
       "  0.33154377341270447,\n",
       "  0.32052382826805115,\n",
       "  0.2961013913154602,\n",
       "  0.3064590394496918,\n",
       "  0.27880772948265076,\n",
       "  0.28958603739738464,\n",
       "  0.2639373242855072,\n",
       "  0.2758401036262512,\n",
       "  0.26822996139526367,\n",
       "  0.2413368970155716,\n",
       "  0.2583642899990082,\n",
       "  0.2340986132621765,\n",
       "  0.2427712231874466,\n",
       "  0.2255072146654129,\n",
       "  0.24851305782794952,\n",
       "  0.2229711413383484,\n",
       "  0.22919327020645142,\n",
       "  0.22225871682167053,\n",
       "  0.2344139963388443,\n",
       "  0.22335782647132874,\n",
       "  0.2246287316083908,\n",
       "  0.22110018134117126,\n",
       "  0.22163185477256775,\n",
       "  0.2186255007982254,\n",
       "  0.22861827909946442,\n",
       "  0.21537227928638458,\n",
       "  0.21839213371276855,\n",
       "  0.21695898473262787,\n",
       "  0.2123844474554062,\n",
       "  0.21883399784564972,\n",
       "  0.22530151903629303,\n",
       "  0.22212664783000946,\n",
       "  0.21500539779663086,\n",
       "  0.21702206134796143,\n",
       "  0.2372511923313141,\n",
       "  0.2104620486497879,\n",
       "  0.2280319482088089,\n",
       "  0.216407909989357,\n",
       "  0.22256910800933838,\n",
       "  0.2234666347503662,\n",
       "  0.2118840366601944,\n",
       "  0.2139965146780014,\n",
       "  0.2250436693429947,\n",
       "  0.2163267880678177,\n",
       "  0.22470448911190033,\n",
       "  0.22211842238903046,\n",
       "  0.21799547970294952,\n",
       "  0.2131676822900772,\n",
       "  0.2273172289133072,\n",
       "  0.22227905690670013,\n",
       "  0.2477826476097107,\n",
       "  0.218565434217453,\n",
       "  0.22751589119434357,\n",
       "  0.21710991859436035,\n",
       "  0.22520798444747925,\n",
       "  0.22470632195472717,\n",
       "  0.2338458001613617,\n",
       "  0.22287645936012268,\n",
       "  0.24427878856658936,\n",
       "  0.22509326040744781,\n",
       "  0.23939770460128784,\n",
       "  0.2220485806465149,\n",
       "  0.24897615611553192,\n",
       "  0.23031814396381378,\n",
       "  0.2380349338054657,\n",
       "  0.22670020163059235,\n",
       "  0.2604137659072876,\n",
       "  0.23489224910736084,\n",
       "  0.25176817178726196,\n",
       "  0.23213225603103638,\n",
       "  0.2316575050354004,\n",
       "  0.2314174324274063,\n",
       "  0.2550950348377228,\n",
       "  0.22512100636959076,\n",
       "  0.2344723492860794,\n",
       "  0.23665383458137512,\n",
       "  0.2426745742559433,\n",
       "  0.23690028488636017,\n",
       "  0.2372550517320633,\n",
       "  0.24134735763072968,\n",
       "  0.2385321408510208,\n",
       "  0.2467811554670334,\n",
       "  0.2356462925672531,\n",
       "  0.24617066979408264,\n",
       "  0.240212082862854,\n",
       "  0.2492733746767044,\n",
       "  0.26201871037483215,\n",
       "  0.2450910359621048,\n",
       "  0.2361874133348465,\n",
       "  0.2466677576303482,\n",
       "  0.2580468952655792,\n",
       "  0.24625463783740997,\n",
       "  0.2346230298280716,\n",
       "  0.24086971580982208,\n",
       "  0.24790899455547333,\n",
       "  0.24492669105529785,\n",
       "  0.24705179035663605,\n",
       "  0.24902279675006866,\n",
       "  0.24482449889183044,\n",
       "  0.2511230707168579,\n",
       "  0.24751244485378265,\n",
       "  0.2591623365879059,\n",
       "  0.23035870492458344,\n",
       "  0.268753319978714,\n",
       "  0.2333744615316391,\n",
       "  0.23051080107688904,\n",
       "  0.2535465955734253,\n",
       "  0.23349623382091522,\n",
       "  0.2534947395324707,\n",
       "  0.23781774938106537,\n",
       "  0.23824641108512878,\n",
       "  0.24581116437911987,\n",
       "  0.24019187688827515,\n",
       "  0.25924548506736755,\n",
       "  0.2531813979148865,\n",
       "  0.2678822875022888,\n",
       "  0.251887708902359,\n",
       "  0.25789719820022583,\n",
       "  0.2426733374595642,\n",
       "  0.28702086210250854,\n",
       "  0.2555517554283142,\n",
       "  0.2420058697462082,\n",
       "  0.265302836894989,\n",
       "  0.25697559118270874,\n",
       "  0.26982057094573975,\n",
       "  0.26200252771377563,\n",
       "  0.2734512388706207,\n",
       "  0.25990742444992065,\n",
       "  0.3063187003135681,\n",
       "  0.26715782284736633,\n",
       "  0.27923697233200073,\n",
       "  0.27583685517311096,\n",
       "  0.29518720507621765,\n",
       "  0.25918328762054443,\n",
       "  0.27377966046333313,\n",
       "  0.26272737979888916,\n",
       "  0.28041887283325195,\n",
       "  0.27140629291534424,\n",
       "  0.31006693840026855,\n",
       "  0.2690533399581909,\n",
       "  0.30218207836151123,\n",
       "  0.27665767073631287,\n",
       "  0.3029498755931854,\n",
       "  0.2773986756801605,\n",
       "  0.29051220417022705,\n",
       "  0.2810415029525757,\n",
       "  0.31574830412864685,\n",
       "  0.2971879243850708,\n",
       "  0.32767418026924133,\n",
       "  0.29690223932266235,\n",
       "  0.30596449971199036,\n",
       "  0.3002963364124298,\n",
       "  0.29024747014045715,\n",
       "  0.30383703112602234,\n",
       "  0.29239293932914734,\n",
       "  0.3157867193222046,\n",
       "  0.30261778831481934,\n",
       "  0.32941287755966187,\n",
       "  0.29638537764549255,\n",
       "  0.3108711540699005,\n",
       "  0.316738486289978,\n",
       "  0.3207417130470276,\n",
       "  0.3228684961795807,\n",
       "  0.31480950117111206,\n",
       "  0.28613707423210144,\n",
       "  0.3138628304004669,\n",
       "  0.3081953823566437,\n",
       "  0.3211313486099243,\n",
       "  0.31818127632141113,\n",
       "  0.3175005316734314,\n",
       "  0.33272919058799744,\n",
       "  0.32687926292419434,\n",
       "  0.3361738622188568,\n",
       "  0.3200719654560089,\n",
       "  0.347109854221344,\n",
       "  0.34147852659225464,\n",
       "  0.32782894372940063,\n",
       "  0.34883180260658264,\n",
       "  0.3109019994735718,\n",
       "  0.3268702030181885,\n",
       "  0.35095900297164917,\n",
       "  0.3295533061027527,\n",
       "  0.33903738856315613,\n",
       "  0.32816505432128906,\n",
       "  0.36804288625717163,\n",
       "  0.33973798155784607,\n",
       "  0.3607790470123291,\n",
       "  0.3573184907436371,\n",
       "  0.3518370985984802,\n",
       "  0.3424985408782959,\n",
       "  0.3648957908153534,\n",
       "  0.3776736557483673,\n",
       "  0.34243592619895935,\n",
       "  0.3536904752254486,\n",
       "  0.3703010380268097,\n",
       "  0.36789408326148987,\n",
       "  0.37343356013298035,\n",
       "  0.36697670817375183,\n",
       "  0.3786466717720032,\n",
       "  0.35335052013397217,\n",
       "  0.40396648645401,\n",
       "  0.35176408290863037,\n",
       "  0.36295831203460693,\n",
       "  0.3754502236843109,\n",
       "  0.34720084071159363,\n",
       "  0.3998412489891052,\n",
       "  0.3627654016017914,\n",
       "  0.37207892537117004,\n",
       "  0.3629133403301239,\n",
       "  0.3592040538787842,\n",
       "  0.3571682274341583,\n",
       "  0.3507194519042969,\n",
       "  0.36910396814346313,\n",
       "  0.3514308035373688,\n",
       "  0.3581332862377167,\n",
       "  0.360629141330719,\n",
       "  0.35352158546447754,\n",
       "  0.3486432433128357,\n",
       "  0.3782513439655304,\n",
       "  0.37485238909721375,\n",
       "  0.3321775794029236,\n",
       "  0.32804074883461,\n",
       "  0.3388197720050812,\n",
       "  0.37021079659461975,\n",
       "  0.35136231780052185,\n",
       "  0.36752384901046753,\n",
       "  0.3790986239910126,\n",
       "  0.36353760957717896,\n",
       "  0.36326536536216736,\n",
       "  0.3777903616428375,\n",
       "  0.3737601339817047,\n",
       "  0.3495551347732544,\n",
       "  0.3761068880558014,\n",
       "  0.36033254861831665,\n",
       "  0.3675820827484131,\n",
       "  0.38534635305404663,\n",
       "  0.3714801073074341,\n",
       "  0.3800642192363739,\n",
       "  0.37658265233039856,\n",
       "  0.3780130445957184,\n",
       "  0.37871989607810974,\n",
       "  0.36769700050354004,\n",
       "  0.41217368841171265,\n",
       "  0.371156245470047,\n",
       "  0.3984237313270569,\n",
       "  0.38081613183021545,\n",
       "  0.3905251622200012,\n",
       "  0.3698969781398773,\n",
       "  0.3792596459388733,\n",
       "  0.36850106716156006,\n",
       "  0.3704335391521454,\n",
       "  0.35946980118751526,\n",
       "  0.38004595041275024,\n",
       "  0.3755718767642975,\n",
       "  0.3855228126049042,\n",
       "  0.3823620676994324,\n",
       "  0.38249215483665466,\n",
       "  0.3890865445137024,\n",
       "  0.3797876238822937,\n",
       "  0.38218456506729126,\n",
       "  0.39004096388816833,\n",
       "  0.38087350130081177,\n",
       "  0.38988611102104187,\n",
       "  0.39702606201171875,\n",
       "  0.3859464228153229,\n",
       "  0.40960970520973206,\n",
       "  0.3889239728450775,\n",
       "  0.39464688301086426,\n",
       "  0.40092843770980835,\n",
       "  0.3917674720287323,\n",
       "  0.40101489424705505,\n",
       "  0.38581663370132446,\n",
       "  0.36895161867141724,\n",
       "  0.3812590539455414,\n",
       "  0.3698050379753113,\n",
       "  0.3765779137611389,\n",
       "  0.38958045840263367,\n",
       "  0.396501749753952,\n",
       "  0.3956160247325897,\n",
       "  0.40706783533096313,\n",
       "  0.4014025032520294,\n",
       "  0.40832191705703735,\n",
       "  0.39600256085395813,\n",
       "  0.4075886607170105,\n",
       "  0.41789379715919495,\n",
       "  0.4136236906051636,\n",
       "  0.4104074537754059,\n",
       "  0.4196353256702423,\n",
       "  0.4085034132003784,\n",
       "  0.4183793067932129,\n",
       "  0.40734395384788513,\n",
       "  0.4138410687446594,\n",
       "  0.4145539700984955,\n",
       "  0.4174744486808777,\n",
       "  0.41320472955703735,\n",
       "  0.4257326126098633,\n",
       "  0.4170725643634796,\n",
       "  0.42467987537384033,\n",
       "  0.4226148724555969,\n",
       "  0.42520871758461,\n",
       "  0.41879507899284363,\n",
       "  0.4275473356246948,\n",
       "  0.42333918809890747,\n",
       "  0.43292590975761414,\n",
       "  0.44191792607307434,\n",
       "  0.41739746928215027,\n",
       "  0.4185687005519867,\n",
       "  0.41751283407211304,\n",
       "  0.4186703860759735,\n",
       "  0.42347443103790283,\n",
       "  0.42837825417518616,\n",
       "  0.4270184636116028,\n",
       "  0.42920634150505066,\n",
       "  0.43819645047187805,\n",
       "  0.4360835552215576,\n",
       "  0.44938594102859497,\n",
       "  0.43621039390563965,\n",
       "  0.43969041109085083,\n",
       "  0.4392586946487427,\n",
       "  0.4443304240703583,\n",
       "  0.44563308358192444,\n",
       "  0.4330282509326935,\n",
       "  0.44293734431266785,\n",
       "  0.4373418986797333,\n",
       "  0.4417513310909271,\n",
       "  0.44290268421173096,\n",
       "  0.4519951641559601,\n",
       "  0.44391414523124695,\n",
       "  0.43913334608078003,\n",
       "  0.42116791009902954,\n",
       "  0.44265279173851013,\n",
       "  0.4199707508087158,\n",
       "  0.4263213276863098,\n",
       "  0.42520973086357117,\n",
       "  0.42271044850349426,\n",
       "  0.42859748005867004,\n",
       "  0.4248000979423523,\n",
       "  0.43819287419319153,\n",
       "  0.43373650312423706,\n",
       "  0.43392106890678406,\n",
       "  0.44684088230133057,\n",
       "  0.4361884891986847,\n",
       "  0.44403237104415894,\n",
       "  0.4551224112510681,\n",
       "  0.4259510934352875,\n",
       "  0.4423506259918213,\n",
       "  0.430691123008728,\n",
       "  0.4733896851539612,\n",
       "  0.429513543844223,\n",
       "  0.4394628405570984,\n",
       "  0.4382930397987366,\n",
       "  0.434230238199234,\n",
       "  0.45523279905319214,\n",
       "  0.4463798701763153,\n",
       "  0.45494019985198975,\n",
       "  0.4525916278362274,\n",
       "  0.448554128408432,\n",
       "  0.4574405550956726,\n",
       "  0.44207873940467834,\n",
       "  0.4451143741607666,\n",
       "  0.45915818214416504,\n",
       "  0.46674537658691406,\n",
       "  0.4565628468990326,\n",
       "  0.46030300855636597,\n",
       "  0.45733657479286194,\n",
       "  0.45680707693099976,\n",
       "  0.4628942310810089,\n",
       "  0.45348137617111206,\n",
       "  0.4704242944717407,\n",
       "  0.45920461416244507,\n",
       "  0.46079304814338684,\n",
       "  0.46892228722572327,\n",
       "  0.46733930706977844,\n",
       "  0.4636826813220978,\n",
       "  0.4730910360813141,\n",
       "  0.46399882435798645,\n",
       "  0.47310033440589905,\n",
       "  0.47413399815559387,\n",
       "  0.47571083903312683,\n",
       "  0.46734434366226196,\n",
       "  0.503165066242218,\n",
       "  0.46633273363113403,\n",
       "  0.5116980671882629,\n",
       "  0.45880863070487976,\n",
       "  0.4682149589061737,\n",
       "  0.46337413787841797,\n",
       "  0.47680845856666565,\n",
       "  0.4770260751247406,\n",
       "  0.49203482270240784,\n",
       "  0.47733673453330994,\n",
       "  0.4975394010543823,\n",
       "  0.48687297105789185,\n",
       "  0.48930954933166504,\n",
       "  0.4891015589237213,\n",
       "  0.48685675859451294,\n",
       "  0.4912041425704956,\n",
       "  0.48869407176971436,\n",
       "  0.49025171995162964,\n",
       "  0.49303552508354187,\n",
       "  0.4942300617694855,\n",
       "  0.49856036901474,\n",
       "  0.4937424659729004,\n",
       "  0.49558067321777344,\n",
       "  0.5064592361450195,\n",
       "  0.48958948254585266,\n",
       "  0.500009298324585,\n",
       "  0.4866613745689392,\n",
       "  0.48588109016418457,\n",
       "  0.49367061257362366,\n",
       "  0.49376311898231506,\n",
       "  0.5234953165054321,\n",
       "  0.4935862720012665,\n",
       "  0.503921389579773,\n",
       "  0.5031813383102417,\n",
       "  0.4929506778717041,\n",
       "  0.5105254650115967,\n",
       "  0.5042192935943604,\n",
       "  0.5155585408210754,\n",
       "  0.4998266398906708,\n",
       "  0.5049237608909607,\n",
       "  0.5082388520240784,\n",
       "  0.501166045665741,\n",
       "  0.5180918574333191,\n",
       "  0.507810652256012,\n",
       "  0.5119783282279968,\n",
       "  0.5083720088005066,\n",
       "  0.5150712728500366,\n",
       "  0.5123178958892822,\n",
       "  0.5085600018501282,\n",
       "  0.5090179443359375,\n",
       "  0.5293503999710083,\n",
       "  0.506781816482544,\n",
       "  0.5286235213279724,\n",
       "  0.5071319341659546,\n",
       "  0.5190279483795166,\n",
       "  0.5194940567016602,\n",
       "  0.5135222673416138,\n",
       "  0.5216187834739685,\n",
       "  0.5209689140319824,\n",
       "  0.5219640731811523,\n",
       "  0.5170913338661194,\n",
       "  0.517844021320343,\n",
       "  0.5283907651901245,\n",
       "  0.5181201100349426,\n",
       "  0.5158616304397583,\n",
       "  0.5271474123001099,\n",
       "  0.5266801714897156,\n",
       "  0.5193222761154175,\n",
       "  0.535648763179779,\n",
       "  0.5240337252616882,\n",
       "  0.5292821526527405,\n",
       "  0.5380693674087524,\n",
       "  0.5275981426239014,\n",
       "  0.525536298751831,\n",
       "  0.5377978682518005,\n",
       "  0.5250791311264038,\n",
       "  0.5244865417480469,\n",
       "  0.528577983379364,\n",
       "  0.5281885266304016,\n",
       "  0.5265374779701233,\n",
       "  0.5297807455062866,\n",
       "  0.5341807007789612,\n",
       "  0.5277085304260254,\n",
       "  0.5333449840545654,\n",
       "  0.5316937565803528,\n",
       "  0.5370267033576965,\n",
       "  0.5389343500137329,\n",
       "  0.5420536994934082,\n",
       "  0.5355378985404968,\n",
       "  0.5436187982559204,\n",
       "  0.5351370573043823,\n",
       "  0.5472760200500488,\n",
       "  0.540515124797821,\n",
       "  0.5443049669265747,\n",
       "  0.5456104874610901,\n",
       "  0.5484341979026794,\n",
       "  0.5533905625343323,\n",
       "  0.5469461679458618,\n",
       "  0.5456546545028687,\n",
       "  0.5528601408004761,\n",
       "  0.5499780774116516,\n",
       "  0.550787091255188,\n",
       "  0.5500525236129761,\n",
       "  0.5488176941871643,\n",
       "  0.5559994578361511,\n",
       "  0.5499828457832336,\n",
       "  0.5576135516166687,\n",
       "  0.562325656414032,\n",
       "  0.5515956282615662,\n",
       "  0.5685696005821228,\n",
       "  0.5449701547622681,\n",
       "  0.5466094017028809,\n",
       "  0.5505004525184631,\n",
       "  0.5550628900527954,\n",
       "  0.5613798499107361,\n",
       "  0.5572683811187744,\n",
       "  0.567086935043335,\n",
       "  0.565727174282074,\n",
       "  0.5679993033409119,\n",
       "  0.5772475600242615,\n",
       "  0.5620272755622864,\n",
       "  0.5712133049964905,\n",
       "  0.563604474067688,\n",
       "  0.5700166821479797,\n",
       "  0.5672224760055542,\n",
       "  0.5640501976013184,\n",
       "  0.569375216960907,\n",
       "  0.5701068639755249,\n",
       "  0.5706679224967957,\n",
       "  0.5738336443901062,\n",
       "  0.5652025938034058,\n",
       "  0.5879944562911987,\n",
       "  0.5657757520675659,\n",
       "  0.5847062468528748,\n",
       "  0.5653097629547119,\n",
       "  0.5774600505828857,\n",
       "  0.5634064674377441,\n",
       "  0.5860873460769653,\n",
       "  0.5703696608543396,\n",
       "  0.5668540596961975,\n",
       "  0.5809914469718933,\n",
       "  0.5811301469802856,\n",
       "  0.5838692784309387,\n",
       "  0.5772095918655396,\n",
       "  0.5833724737167358,\n",
       "  0.582293689250946,\n",
       "  0.5893424153327942,\n",
       "  0.5859090089797974,\n",
       "  0.5863280296325684,\n",
       "  0.5856210589408875,\n",
       "  0.5878109931945801,\n",
       "  0.5908358693122864,\n",
       "  0.5909884572029114,\n",
       "  0.5943097472190857,\n",
       "  0.5879092812538147,\n",
       "  0.5843737721443176,\n",
       "  0.5854316353797913,\n",
       "  0.5871700644493103,\n",
       "  0.5813808441162109,\n",
       "  0.5932255983352661,\n",
       "  0.5931305885314941,\n",
       "  0.5965891480445862,\n",
       "  0.599676787853241,\n",
       "  0.5927053689956665,\n",
       "  0.5967847108840942,\n",
       "  0.5959256291389465,\n",
       "  0.5957586765289307,\n",
       "  0.5940544009208679,\n",
       "  0.6009933948516846,\n",
       "  0.6010140776634216,\n",
       "  0.5973489284515381,\n",
       "  0.6042817831039429,\n",
       "  0.6005827784538269,\n",
       "  0.609725296497345,\n",
       "  0.6016475558280945,\n",
       "  0.6085347533226013,\n",
       "  0.5991502404212952,\n",
       "  0.608738124370575,\n",
       "  0.6013230681419373,\n",
       "  0.6012443900108337,\n",
       "  0.6068122982978821,\n",
       "  0.6077161431312561,\n",
       "  0.6054099798202515,\n",
       "  0.6117963790893555,\n",
       "  0.6035241484642029,\n",
       "  0.610685408115387,\n",
       "  0.6113735437393188,\n",
       "  0.6129941940307617,\n",
       "  0.6104822754859924,\n",
       "  0.6163724064826965,\n",
       "  0.6177281141281128,\n",
       "  0.6130203604698181,\n",
       "  0.6215788125991821,\n",
       "  0.6174343824386597,\n",
       "  0.6197099089622498,\n",
       "  0.6212071180343628,\n",
       "  0.6178488731384277,\n",
       "  0.627467691898346,\n",
       "  0.6201347708702087,\n",
       "  0.6189199090003967,\n",
       "  0.6204930543899536,\n",
       "  0.622907817363739,\n",
       "  0.6258703470230103,\n",
       "  0.6260993480682373,\n",
       "  0.6257613301277161,\n",
       "  0.6274702548980713,\n",
       "  0.6299682855606079,\n",
       "  0.6336109042167664,\n",
       "  0.6246499419212341,\n",
       "  0.6336789131164551,\n",
       "  0.6307314038276672,\n",
       "  0.6285662055015564,\n",
       "  0.6338330507278442,\n",
       "  0.6307291388511658,\n",
       "  0.637912929058075,\n",
       "  0.6378544569015503,\n",
       "  0.6273106932640076,\n",
       "  0.644427478313446,\n",
       "  0.6306024789810181,\n",
       "  0.6350385546684265,\n",
       "  0.6404902338981628,\n",
       "  0.6540976166725159,\n",
       "  0.6298775672912598,\n",
       "  0.6408209800720215,\n",
       "  0.6391674876213074,\n",
       "  0.637017011642456,\n",
       "  0.639573872089386,\n",
       "  0.6381061673164368,\n",
       "  0.6430729031562805,\n",
       "  0.6435075998306274,\n",
       "  0.6425029635429382,\n",
       "  0.6414824724197388,\n",
       "  0.6447024345397949,\n",
       "  0.6469470262527466,\n",
       "  0.639183759689331,\n",
       "  0.6409406661987305,\n",
       "  0.6388524174690247,\n",
       "  0.6384028792381287,\n",
       "  0.6397661566734314,\n",
       "  0.6389938592910767,\n",
       "  0.6417756676673889,\n",
       "  0.6416131854057312,\n",
       "  0.6429415941238403,\n",
       "  0.6402809023857117,\n",
       "  0.6424275636672974,\n",
       "  0.6444386839866638,\n",
       "  0.6419078707695007,\n",
       "  0.6409818530082703,\n",
       "  0.6457187533378601,\n",
       "  0.6464369297027588,\n",
       "  0.6485576033592224,\n",
       "  0.6503944396972656,\n",
       "  0.6478598117828369,\n",
       "  0.6515471935272217,\n",
       "  0.6518566012382507,\n",
       "  0.6498995423316956,\n",
       "  0.6559754610061646,\n",
       "  0.6501688361167908,\n",
       "  0.6579276919364929,\n",
       "  0.6535284519195557,\n",
       "  0.6567437052726746,\n",
       "  0.6574299931526184,\n",
       "  0.6554550528526306,\n",
       "  0.6525217294692993,\n",
       "  0.662982702255249,\n",
       "  0.6556104421615601,\n",
       "  0.65960294008255,\n",
       "  0.66070955991745,\n",
       "  0.6569441556930542,\n",
       "  0.6738942861557007,\n",
       "  0.6625292897224426,\n",
       "  0.6708459854125977,\n",
       "  0.6630491614341736,\n",
       "  0.6626784205436707,\n",
       "  0.6747987866401672,\n",
       "  0.6603599786758423,\n",
       "  0.6649614572525024,\n",
       "  0.6651875376701355,\n",
       "  0.6654340624809265,\n",
       "  0.6704325079917908,\n",
       "  0.6694561243057251,\n",
       "  0.672193169593811,\n",
       "  0.6729294061660767,\n",
       "  0.669221043586731,\n",
       "  0.6686781644821167,\n",
       "  0.6778136491775513,\n",
       "  0.6730098724365234,\n",
       "  0.6783902645111084,\n",
       "  0.6778870820999146,\n",
       "  0.6765033006668091,\n",
       "  0.6759479641914368,\n",
       "  0.6824480295181274,\n",
       "  0.6777857542037964,\n",
       "  0.6798192858695984,\n",
       "  0.6810462474822998,\n",
       "  0.6808199286460876,\n",
       "  0.6799530982971191,\n",
       "  0.6844785213470459,\n",
       "  0.673984706401825,\n",
       "  0.6830963492393494,\n",
       "  0.6761298179626465,\n",
       "  0.6797379851341248,\n",
       "  0.6845468282699585,\n",
       "  0.6810863614082336,\n",
       "  0.6820977330207825,\n",
       "  0.6830393671989441,\n",
       "  0.685400128364563,\n",
       "  0.6848519444465637,\n",
       "  0.6860989332199097]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93040057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelKaybi = pd.DataFrame(model.history.history)\n",
    "modelKaybi.plot()\n",
    "# epochs=700 için overfitting oluyor. Validation loss azalması gerekirken artıyor.\n",
    "# val_loss eğer çok saçma yerlere gitmeye başlarsa EarlyStopping sınıfı kullanılabilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4adcca4",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed05aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7030 - val_loss: 0.6937\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 0.6922\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6914 - val_loss: 0.6908\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6850 - val_loss: 0.6890\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6775 - val_loss: 0.6879\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 0.6876\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6634 - val_loss: 0.6866\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6708 - val_loss: 0.6846\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6693 - val_loss: 0.6826\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6683 - val_loss: 0.6810\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6605 - val_loss: 0.6795\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6728 - val_loss: 0.6784\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6602 - val_loss: 0.6779\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6376 - val_loss: 0.6765\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6437 - val_loss: 0.6739\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6507 - val_loss: 0.6722\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6418 - val_loss: 0.6702\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6328 - val_loss: 0.6665\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6331 - val_loss: 0.6619\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6371 - val_loss: 0.6594\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.594 - 0s 2ms/step - loss: 0.6192 - val_loss: 0.6578\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6360 - val_loss: 0.6511\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6457\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6372\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6289\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.6201\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5888 - val_loss: 0.6143\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 0.6104\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 0.6055\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5873 - val_loss: 0.5998\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.5872\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5711 - val_loss: 0.5712\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5610\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5747 - val_loss: 0.5543\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5564 - val_loss: 0.5440\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5648 - val_loss: 0.5307\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5430 - val_loss: 0.5253\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5317 - val_loss: 0.5232\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5214 - val_loss: 0.5077\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4854 - val_loss: 0.4957\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5139 - val_loss: 0.4846\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5115 - val_loss: 0.4818\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4832 - val_loss: 0.4752\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.4553\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.4364\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5036 - val_loss: 0.4311\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.4183\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4700 - val_loss: 0.4124\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.4085\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4275 - val_loss: 0.3956\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.3915\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.3881\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3944 - val_loss: 0.3736\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.3592\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.3535\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3535\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3569 - val_loss: 0.3537\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3789 - val_loss: 0.3372\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.3423\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.3534\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3606 - val_loss: 0.3433\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3274\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.3235\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3661 - val_loss: 0.3353\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3462\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3228\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.3070\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3318\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2992 - val_loss: 0.3193\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.3160\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2951 - val_loss: 0.3255\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3140 - val_loss: 0.3240\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3221 - val_loss: 0.3238\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.3211\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3114 - val_loss: 0.3189\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3244 - val_loss: 0.2955\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3072 - val_loss: 0.3000\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3065 - val_loss: 0.3028\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.3015\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2711 - val_loss: 0.3064\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2699 - val_loss: 0.3118\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.2954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2849 - val_loss: 0.3035\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3035 - val_loss: 0.2902\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2741 - val_loss: 0.2842\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2687 - val_loss: 0.2802\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - val_loss: 0.2868\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2746 - val_loss: 0.2918\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2358 - val_loss: 0.2941\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2526 - val_loss: 0.2841\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2964 - val_loss: 0.2848\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2345 - val_loss: 0.2952\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.2892\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2254 - val_loss: 0.3009\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2574 - val_loss: 0.3038\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2523 - val_loss: 0.2870\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2495 - val_loss: 0.2729\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2377 - val_loss: 0.2769\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2561 - val_loss: 0.2830\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2283 - val_loss: 0.2794\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2345 - val_loss: 0.2826\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2477 - val_loss: 0.2899\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2534 - val_loss: 0.2783\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2626 - val_loss: 0.2830\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2894\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2329 - val_loss: 0.3079\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2325 - val_loss: 0.3030\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.3010\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2019 - val_loss: 0.3082\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2051 - val_loss: 0.3170\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.3208\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2414 - val_loss: 0.2948\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2289 - val_loss: 0.2877\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1795 - val_loss: 0.3005\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2076 - val_loss: 0.3195\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2520 - val_loss: 0.3084\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2201 - val_loss: 0.3139\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2018 - val_loss: 0.3086\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2133 - val_loss: 0.3064\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2311 - val_loss: 0.2950\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2069 - val_loss: 0.2996\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2061 - val_loss: 0.3108\n",
      "Epoch 00122: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23bcbce9e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential() # model oluşturuyoruz\n",
    "model.add(Dense(units=30,activation=\"relu\")) # içeriğe 30 tane nöron koy, genelde de kolon sayısı kadar nöron koyulur.\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=15,activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "#sınıflandırma problemlerinde sigmoid kullanılır çünkü çıkışları 1 veya 0'dır\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\")\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=25)\n",
    "model.fit(x=x_train,y=y_train, epochs=700, validation_data= (x_test,y_test),verbose=1,callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cc086f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelKaybi=pd.DataFrame(model.history.history)\n",
    "modelKaybi.plot()\n",
    "# Earlystopping oldu ve overfitting olmadan bitti. Daha iyi sonuç elde etmek için Dropout kullanacağız"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6204a6",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da993f",
   "metadata": {},
   "source": [
    "Layerler ile ilgili bir overfitting yaşıyorsak onları atarak daha verimli bir hale getirir ve validation loss daha iyi duruma gelir. EarlyStopping kısmına kod olarak ekledik. Eğer içine bir değer yazmazsak bir sonuç almayız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2f11f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-194ec0ff0f2a>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tahminlerimiz= model.predict_classes(x_test)\n",
    "tahminlerimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a1c42bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        91\n",
      "           1       0.94      0.81      0.87        74\n",
      "\n",
      "    accuracy                           0.89       165\n",
      "   macro avg       0.90      0.88      0.89       165\n",
      "weighted avg       0.90      0.89      0.89       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,tahminlerimiz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e643bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  4]\n",
      " [14 60]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,tahminlerimiz)) # 4 değer yanlış diğerleri doğru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcc23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
